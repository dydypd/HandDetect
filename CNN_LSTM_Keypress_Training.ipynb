{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5aea25be",
   "metadata": {},
   "source": [
    "# CNN + LSTM Model for Key Press Detection\n",
    "\n",
    "This notebook trains a CNN+LSTM model to detect key press events from video sequences. The model combines:\n",
    "- **CNN**: Extracts spatial features from key region images\n",
    "- **LSTM**: Models temporal patterns for key press detection\n",
    "\n",
    "## Dataset Structure\n",
    "The training data comes from the video labeler application with the following format:\n",
    "- Image sequences (64x64x3) of key regions\n",
    "- Binary labels (0: not pressed, 1: pressed)\n",
    "- Temporal ordering for sequence modeling\n",
    "\n",
    "## Model Architecture\n",
    "1. **Feature Extraction**: CNN processes individual frames\n",
    "2. **Temporal Modeling**: LSTM learns temporal patterns\n",
    "3. **Classification**: Dense layer outputs key press probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9c41b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import cv2\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"GPU available:\", tf.config.experimental.list_physical_devices('GPU'))\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1559207a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and Preprocess Training Data\n",
    "def load_training_data(data_dir=\"labeled_data\"):\n",
    "    \"\"\"Load training data from JSON files exported by video labeler.\"\"\"\n",
    "    \n",
    "    # Find all training data files\n",
    "    json_files = glob.glob(os.path.join(data_dir, \"training_data_*.json\"))\n",
    "    \n",
    "    if not json_files:\n",
    "        raise FileNotFoundError(f\"No training data found in {data_dir}\")\n",
    "    \n",
    "    all_images = []\n",
    "    all_labels = []\n",
    "    all_frame_indices = []\n",
    "    \n",
    "    print(f\"Found {len(json_files)} training data files:\")\n",
    "    \n",
    "    for json_file in json_files:\n",
    "        print(f\"Loading: {json_file}\")\n",
    "        \n",
    "        with open(json_file, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        # Extract sequence data\n",
    "        sequence_data = data['sequence_data']\n",
    "        \n",
    "        for item in sequence_data:\n",
    "            # Convert image list back to numpy array\n",
    "            image = np.array(item['image'], dtype=np.float32)\n",
    "            \n",
    "            # Ensure image is in correct format (64, 64, 3)\n",
    "            if image.shape != (64, 64, 3):\n",
    "                print(f\"Warning: Invalid image shape {image.shape}, skipping...\")\n",
    "                continue\n",
    "                \n",
    "            all_images.append(image)\n",
    "            all_labels.append(item['label'])\n",
    "            all_frame_indices.append(item['frame_idx'])\n",
    "        \n",
    "        print(f\"  - Loaded {len(sequence_data)} samples\")\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    X = np.array(all_images)\n",
    "    y = np.array(all_labels)\n",
    "    frame_indices = np.array(all_frame_indices)\n",
    "    \n",
    "    print(f\"\\nTotal dataset:\")\n",
    "    print(f\"  - Images shape: {X.shape}\")\n",
    "    print(f\"  - Labels shape: {y.shape}\")\n",
    "    print(f\"  - Label distribution: {np.bincount(y)}\")\n",
    "    \n",
    "    return X, y, frame_indices\n",
    "\n",
    "# Load the data\n",
    "try:\n",
    "    X, y, frame_indices = load_training_data()\n",
    "    print(\"Data loaded successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading data: {e}\")\n",
    "    print(\"Please make sure you have exported training data from the video labeler.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b197740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Exploration and Visualization\n",
    "def visualize_dataset(X, y, frame_indices, num_samples=8):\n",
    "    \"\"\"Visualize sample images and analyze dataset.\"\"\"\n",
    "    \n",
    "    if len(X) == 0:\n",
    "        print(\"No data to visualize\")\n",
    "        return\n",
    "    \n",
    "    # Plot sample images\n",
    "    fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "    fig.suptitle('Sample Key Region Images', fontsize=16)\n",
    "    \n",
    "    # Show samples from each class\n",
    "    pressed_indices = np.where(y == 1)[0]\n",
    "    not_pressed_indices = np.where(y == 0)[0]\n",
    "    \n",
    "    for i in range(4):\n",
    "        # Not pressed samples\n",
    "        if i < len(not_pressed_indices):\n",
    "            idx = not_pressed_indices[i]\n",
    "            axes[0, i].imshow(X[idx])\n",
    "            axes[0, i].set_title(f'Not Pressed (Frame {frame_indices[idx]})')\n",
    "            axes[0, i].axis('off')\n",
    "        \n",
    "        # Pressed samples\n",
    "        if i < len(pressed_indices):\n",
    "            idx = pressed_indices[i]\n",
    "            axes[1, i].imshow(X[idx])\n",
    "            axes[1, i].set_title(f'Pressed (Frame {frame_indices[idx]})')\n",
    "            axes[1, i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Label distribution\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    labels_count = np.bincount(y)\n",
    "    plt.bar(['Not Pressed', 'Pressed'], labels_count, \n",
    "            color=['lightcoral', 'lightgreen'])\n",
    "    plt.title('Label Distribution')\n",
    "    plt.ylabel('Count')\n",
    "    \n",
    "    # Add percentage labels\n",
    "    total = len(y)\n",
    "    for i, count in enumerate(labels_count):\n",
    "        plt.text(i, count + total*0.01, f'{count}\\n({count/total:.1%})', \n",
    "                ha='center', va='bottom')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.hist(frame_indices, bins=50, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "    plt.title('Frame Index Distribution')\n",
    "    plt.xlabel('Frame Index')\n",
    "    plt.ylabel('Frequency')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Dataset statistics\n",
    "    print(f\"Dataset Statistics:\")\n",
    "    print(f\"  - Total samples: {len(X)}\")\n",
    "    print(f\"  - Image shape: {X.shape[1:]}\")\n",
    "    print(f\"  - Image value range: [{X.min():.3f}, {X.max():.3f}]\")\n",
    "    print(f\"  - Not pressed samples: {labels_count[0]} ({labels_count[0]/total:.1%})\")\n",
    "    print(f\"  - Pressed samples: {labels_count[1]} ({labels_count[1]/total:.1%})\")\n",
    "\n",
    "# Visualize the dataset\n",
    "if 'X' in locals() and len(X) > 0:\n",
    "    visualize_dataset(X, y, frame_indices)\n",
    "else:\n",
    "    print(\"No data available for visualization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc0229e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation and Preprocessing\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def create_data_augmentation():\n",
    "    \"\"\"Create data augmentation pipeline.\"\"\"\n",
    "    \n",
    "    # Define augmentation parameters\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=10,          # Random rotation\n",
    "        width_shift_range=0.1,      # Random horizontal shift\n",
    "        height_shift_range=0.1,     # Random vertical shift\n",
    "        brightness_range=[0.8, 1.2], # Random brightness\n",
    "        zoom_range=0.1,             # Random zoom\n",
    "        horizontal_flip=False,       # No horizontal flip (text orientation)\n",
    "        fill_mode='nearest',        # Fill mode for transformations\n",
    "        rescale=None               # Don't rescale (already normalized)\n",
    "    )\n",
    "    \n",
    "    return datagen\n",
    "\n",
    "def augment_dataset(X, y, augment_factor=2):\n",
    "    \"\"\"Augment dataset to increase sample size.\"\"\"\n",
    "    \n",
    "    if len(X) == 0:\n",
    "        return X, y\n",
    "    \n",
    "    print(f\"Original dataset size: {len(X)}\")\n",
    "    \n",
    "    # Separate classes\n",
    "    pressed_indices = np.where(y == 1)[0]\n",
    "    not_pressed_indices = np.where(y == 0)[0]\n",
    "    \n",
    "    # Balance classes by augmenting minority class\n",
    "    if len(pressed_indices) < len(not_pressed_indices):\n",
    "        minority_class = 1\n",
    "        minority_indices = pressed_indices\n",
    "        majority_indices = not_pressed_indices\n",
    "    else:\n",
    "        minority_class = 0\n",
    "        minority_indices = not_pressed_indices\n",
    "        majority_indices = pressed_indices\n",
    "    \n",
    "    print(f\"Minority class: {minority_class} ({len(minority_indices)} samples)\")\n",
    "    print(f\"Majority class: {1-minority_class} ({len(majority_indices)} samples)\")\n",
    "    \n",
    "    # Create augmentation generator\n",
    "    datagen = create_data_augmentation()\n",
    "    \n",
    "    # Augment minority class\n",
    "    X_minority = X[minority_indices]\n",
    "    y_minority = y[minority_indices]\n",
    "    \n",
    "    # Generate augmented samples\n",
    "    augmented_X = []\n",
    "    augmented_y = []\n",
    "    \n",
    "    target_size = len(majority_indices)\n",
    "    samples_needed = target_size - len(minority_indices)\n",
    "    \n",
    "    if samples_needed > 0:\n",
    "        samples_per_original = samples_needed // len(minority_indices) + 1\n",
    "        \n",
    "        for i, (img, label) in enumerate(zip(X_minority, y_minority)):\n",
    "            # Add original sample\n",
    "            augmented_X.append(img)\n",
    "            augmented_y.append(label)\n",
    "            \n",
    "            # Generate augmented samples\n",
    "            img_batch = np.expand_dims(img, axis=0)\n",
    "            aug_iter = datagen.flow(img_batch, batch_size=1, shuffle=False)\n",
    "            \n",
    "            for _ in range(samples_per_original):\n",
    "                if len(augmented_X) >= target_size:\n",
    "                    break\n",
    "                aug_img = next(aug_iter)[0]\n",
    "                augmented_X.append(aug_img)\n",
    "                augmented_y.append(label)\n",
    "    \n",
    "    # Combine original majority class with augmented minority class\n",
    "    X_balanced = np.concatenate([X[majority_indices], np.array(augmented_X[:target_size])])\n",
    "    y_balanced = np.concatenate([y[majority_indices], np.array(augmented_y[:target_size])])\n",
    "    \n",
    "    # Shuffle the balanced dataset\n",
    "    shuffle_indices = np.random.permutation(len(X_balanced))\n",
    "    X_balanced = X_balanced[shuffle_indices]\n",
    "    y_balanced = y_balanced[shuffle_indices]\n",
    "    \n",
    "    print(f\"Balanced dataset size: {len(X_balanced)}\")\n",
    "    print(f\"New class distribution: {np.bincount(y_balanced)}\")\n",
    "    \n",
    "    return X_balanced, y_balanced\n",
    "\n",
    "def preprocess_data(X, y, balance_classes=True):\n",
    "    \"\"\"Preprocess data for training.\"\"\"\n",
    "    \n",
    "    if len(X) == 0:\n",
    "        return X, y\n",
    "    \n",
    "    # Ensure data is in correct format\n",
    "    X = np.array(X, dtype=np.float32)\n",
    "    y = np.array(y, dtype=np.int32)\n",
    "    \n",
    "    # Clip values to [0, 1] range (should already be normalized)\n",
    "    X = np.clip(X, 0.0, 1.0)\n",
    "    \n",
    "    # Balance classes if requested\n",
    "    if balance_classes:\n",
    "        X, y = augment_dataset(X, y)\n",
    "    \n",
    "    # Convert labels to categorical\n",
    "    y_categorical = keras.utils.to_categorical(y, num_classes=2)\n",
    "    \n",
    "    print(f\"Preprocessed dataset:\")\n",
    "    print(f\"  - X shape: {X.shape}\")\n",
    "    print(f\"  - y shape: {y_categorical.shape}\")\n",
    "    print(f\"  - X range: [{X.min():.3f}, {X.max():.3f}]\")\n",
    "    \n",
    "    return X, y_categorical\n",
    "\n",
    "# Preprocess the data\n",
    "if 'X' in locals() and len(X) > 0:\n",
    "    X_processed, y_processed = preprocess_data(X, y)\n",
    "    print(\"Data preprocessing completed!\")\n",
    "else:\n",
    "    print(\"No data available for preprocessing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b31f0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create CNN Feature Extractor\n",
    "def create_cnn_feature_extractor(input_shape=(64, 64, 3)):\n",
    "    \"\"\"Create CNN model for feature extraction from key region images.\"\"\"\n",
    "    \n",
    "    model = keras.Sequential([\n",
    "        # Input layer\n",
    "        layers.Input(shape=input_shape),\n",
    "        \n",
    "        # First convolutional block\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.25),\n",
    "        \n",
    "        # Second convolutional block\n",
    "        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.25),\n",
    "        \n",
    "        # Third convolutional block\n",
    "        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.25),\n",
    "        \n",
    "        # Fourth convolutional block\n",
    "        layers.Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.25),\n",
    "        \n",
    "        # Global average pooling for feature extraction\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dense(512, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.5)\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create and display CNN feature extractor\n",
    "cnn_feature_extractor = create_cnn_feature_extractor()\n",
    "print(\"CNN Feature Extractor Architecture:\")\n",
    "cnn_feature_extractor.summary()\n",
    "\n",
    "# Test the feature extractor with sample input\n",
    "if 'X_processed' in locals() and len(X_processed) > 0:\n",
    "    sample_input = X_processed[:1]  # Take one sample\n",
    "    features = cnn_feature_extractor(sample_input)\n",
    "    print(f\"\\nFeature extraction test:\")\n",
    "    print(f\"Input shape: {sample_input.shape}\")\n",
    "    print(f\"Output features shape: {features.shape}\")\n",
    "    print(f\"Feature vector size: {features.shape[1]}\")\n",
    "else:\n",
    "    print(\"\\nNo processed data available for testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20590404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build CNN+LSTM Model Architecture\n",
    "def create_cnn_lstm_model(sequence_length=10, input_shape=(64, 64, 3), num_classes=2):\n",
    "    \"\"\"Create CNN+LSTM model for temporal key press detection.\"\"\"\n",
    "    \n",
    "    # Input for sequence of images\n",
    "    sequence_input = layers.Input(shape=(sequence_length,) + input_shape)\n",
    "    \n",
    "    # CNN feature extractor (TimeDistributed to process each frame)\n",
    "    cnn_features = layers.TimeDistributed(layers.Conv2D(32, (3, 3), activation='relu', padding='same'))(sequence_input)\n",
    "    cnn_features = layers.TimeDistributed(layers.BatchNormalization())(cnn_features)\n",
    "    cnn_features = layers.TimeDistributed(layers.Conv2D(32, (3, 3), activation='relu', padding='same'))(cnn_features)\n",
    "    cnn_features = layers.TimeDistributed(layers.MaxPooling2D((2, 2)))(cnn_features)\n",
    "    cnn_features = layers.TimeDistributed(layers.Dropout(0.25))(cnn_features)\n",
    "    \n",
    "    cnn_features = layers.TimeDistributed(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))(cnn_features)\n",
    "    cnn_features = layers.TimeDistributed(layers.BatchNormalization())(cnn_features)\n",
    "    cnn_features = layers.TimeDistributed(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))(cnn_features)\n",
    "    cnn_features = layers.TimeDistributed(layers.MaxPooling2D((2, 2)))(cnn_features)\n",
    "    cnn_features = layers.TimeDistributed(layers.Dropout(0.25))(cnn_features)\n",
    "    \n",
    "    cnn_features = layers.TimeDistributed(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))(cnn_features)\n",
    "    cnn_features = layers.TimeDistributed(layers.BatchNormalization())(cnn_features)\n",
    "    cnn_features = layers.TimeDistributed(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))(cnn_features)\n",
    "    cnn_features = layers.TimeDistributed(layers.MaxPooling2D((2, 2)))(cnn_features)\n",
    "    cnn_features = layers.TimeDistributed(layers.Dropout(0.25))(cnn_features)\n",
    "    \n",
    "    # Global average pooling for each frame\n",
    "    cnn_features = layers.TimeDistributed(layers.GlobalAveragePooling2D())(cnn_features)\n",
    "    cnn_features = layers.TimeDistributed(layers.Dense(256, activation='relu'))(cnn_features)\n",
    "    cnn_features = layers.TimeDistributed(layers.BatchNormalization())(cnn_features)\n",
    "    cnn_features = layers.TimeDistributed(layers.Dropout(0.5))(cnn_features)\n",
    "    \n",
    "    # LSTM layers for temporal modeling\n",
    "    lstm_features = layers.LSTM(128, return_sequences=True, dropout=0.3, recurrent_dropout=0.3)(cnn_features)\n",
    "    lstm_features = layers.LSTM(64, return_sequences=False, dropout=0.3, recurrent_dropout=0.3)(lstm_features)\n",
    "    \n",
    "    # Final classification layers\n",
    "    dense_features = layers.Dense(128, activation='relu')(lstm_features)\n",
    "    dense_features = layers.BatchNormalization()(dense_features)\n",
    "    dense_features = layers.Dropout(0.5)(dense_features)\n",
    "    \n",
    "    dense_features = layers.Dense(64, activation='relu')(dense_features)\n",
    "    dense_features = layers.BatchNormalization()(dense_features)\n",
    "    dense_features = layers.Dropout(0.5)(dense_features)\n",
    "    \n",
    "    # Output layer\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(dense_features)\n",
    "    \n",
    "    # Create model\n",
    "    model = keras.Model(inputs=sequence_input, outputs=outputs)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Alternative: Simpler CNN+LSTM model for single frame prediction\n",
    "def create_simple_cnn_lstm_model(input_shape=(64, 64, 3), num_classes=2):\n",
    "    \"\"\"Create simpler CNN+LSTM model for single frame prediction.\"\"\"\n",
    "    \n",
    "    # Input\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    \n",
    "    # CNN feature extraction\n",
    "    x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = layers.Dropout(0.25)(x)\n",
    "    \n",
    "    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = layers.Dropout(0.25)(x)\n",
    "    \n",
    "    x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    \n",
    "    # Dense layers\n",
    "    x = layers.Dense(256, activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    \n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    \n",
    "    # Output\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "# Create the model (start with simpler version)\n",
    "print(\"Creating CNN+LSTM Model...\")\n",
    "model = create_simple_cnn_lstm_model()\n",
    "\n",
    "print(\"\\nModel Architecture:\")\n",
    "model.summary()\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy', 'precision', 'recall']\n",
    ")\n",
    "\n",
    "print(\"\\nModel compiled successfully!\")\n",
    "print(f\"Total parameters: {model.count_params():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c0dc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Sequential Data for Training\n",
    "def create_sequences(X, y, sequence_length=5):\n",
    "    \"\"\"Create sequences for temporal modeling.\"\"\"\n",
    "    \n",
    "    if len(X) < sequence_length:\n",
    "        print(f\"Warning: Not enough data for sequence length {sequence_length}\")\n",
    "        return X, y\n",
    "    \n",
    "    sequences_X = []\n",
    "    sequences_y = []\n",
    "    \n",
    "    # Create sliding window sequences\n",
    "    for i in range(len(X) - sequence_length + 1):\n",
    "        seq_x = X[i:i + sequence_length]\n",
    "        seq_y = y[i + sequence_length - 1]  # Use last frame's label\n",
    "        \n",
    "        sequences_X.append(seq_x)\n",
    "        sequences_y.append(seq_y)\n",
    "    \n",
    "    return np.array(sequences_X), np.array(sequences_y)\n",
    "\n",
    "def prepare_training_data(X, y, test_size=0.2, validation_size=0.2, use_sequences=False):\n",
    "    \"\"\"Prepare data for training with train/validation/test splits.\"\"\"\n",
    "    \n",
    "    if len(X) == 0:\n",
    "        print(\"No data available for training\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"Preparing training data...\")\n",
    "    print(f\"Original dataset size: {len(X)}\")\n",
    "    \n",
    "    # Create sequences if requested\n",
    "    if use_sequences:\n",
    "        X, y = create_sequences(X, y)\n",
    "        print(f\"Sequence dataset size: {len(X)}\")\n",
    "    \n",
    "    # Split data\n",
    "    X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=42, stratify=y.argmax(axis=1)\n",
    "    )\n",
    "    \n",
    "    # Further split temp into train and validation\n",
    "    val_size_adjusted = validation_size / (1 - test_size)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_temp, y_temp, test_size=val_size_adjusted, random_state=42, \n",
    "        stratify=y_temp.argmax(axis=1)\n",
    "    )\n",
    "    \n",
    "    print(f\"Data splits:\")\n",
    "    print(f\"  - Training: {len(X_train)} samples\")\n",
    "    print(f\"  - Validation: {len(X_val)} samples\")\n",
    "    print(f\"  - Test: {len(X_test)} samples\")\n",
    "    \n",
    "    # Print class distribution for each split\n",
    "    for name, labels in [(\"Training\", y_train), (\"Validation\", y_val), (\"Test\", y_test)]:\n",
    "        class_counts = labels.argmax(axis=1)\n",
    "        unique, counts = np.unique(class_counts, return_counts=True)\n",
    "        print(f\"  - {name} class distribution: {dict(zip(unique, counts))}\")\n",
    "    \n",
    "    return {\n",
    "        'X_train': X_train, 'y_train': y_train,\n",
    "        'X_val': X_val, 'y_val': y_val,\n",
    "        'X_test': X_test, 'y_test': y_test\n",
    "    }\n",
    "\n",
    "def create_data_generators(data_dict, batch_size=32, augment_training=True):\n",
    "    \"\"\"Create data generators for efficient training.\"\"\"\n",
    "    \n",
    "    if augment_training:\n",
    "        # Training data generator with augmentation\n",
    "        train_datagen = ImageDataGenerator(\n",
    "            rotation_range=5,\n",
    "            width_shift_range=0.05,\n",
    "            height_shift_range=0.05,\n",
    "            brightness_range=[0.9, 1.1],\n",
    "            zoom_range=0.05,\n",
    "            horizontal_flip=False,\n",
    "            fill_mode='nearest'\n",
    "        )\n",
    "        \n",
    "        train_generator = train_datagen.flow(\n",
    "            data_dict['X_train'], data_dict['y_train'],\n",
    "            batch_size=batch_size, shuffle=True\n",
    "        )\n",
    "    else:\n",
    "        # Simple batch generator without augmentation\n",
    "        train_generator = tf.data.Dataset.from_tensor_slices(\n",
    "            (data_dict['X_train'], data_dict['y_train'])\n",
    "        ).batch(batch_size).shuffle(1000).prefetch(tf.data.AUTOTUNE)\n",
    "    \n",
    "    # Validation generator (no augmentation)\n",
    "    val_generator = tf.data.Dataset.from_tensor_slices(\n",
    "        (data_dict['X_val'], data_dict['y_val'])\n",
    "    ).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    \n",
    "    return train_generator, val_generator\n",
    "\n",
    "# Prepare the data\n",
    "if 'X_processed' in locals() and len(X_processed) > 0:\n",
    "    # Prepare training data\n",
    "    data_splits = prepare_training_data(X_processed, y_processed, use_sequences=False)\n",
    "    \n",
    "    if data_splits:\n",
    "        # Create data generators\n",
    "        train_gen, val_gen = create_data_generators(data_splits, batch_size=32)\n",
    "        \n",
    "        print(\"Data preparation completed!\")\n",
    "        print(f\"Training steps per epoch: {len(data_splits['X_train']) // 32}\")\n",
    "        print(f\"Validation steps per epoch: {len(data_splits['X_val']) // 32}\")\n",
    "    else:\n",
    "        print(\"Failed to prepare data splits\")\n",
    "else:\n",
    "    print(\"No processed data available for training preparation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71daa06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Model\n",
    "def create_callbacks(model_name=\"keypress_model\"):\n",
    "    \"\"\"Create callbacks for training.\"\"\"\n",
    "    \n",
    "    # Create model directory\n",
    "    model_dir = f\"models/{model_name}\"\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    \n",
    "    callbacks = [\n",
    "        # Model checkpoint - save best model\n",
    "        keras.callbacks.ModelCheckpoint(\n",
    "            filepath=f\"{model_dir}/best_model.h5\",\n",
    "            monitor='val_accuracy',\n",
    "            save_best_only=True,\n",
    "            save_weights_only=False,\n",
    "            mode='max',\n",
    "            verbose=1\n",
    "        ),\n",
    "        \n",
    "        # Early stopping\n",
    "        keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=15,\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        \n",
    "        # Learning rate reduction\n",
    "        keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=7,\n",
    "            min_lr=1e-7,\n",
    "            verbose=1\n",
    "        ),\n",
    "        \n",
    "        # CSV logger\n",
    "        keras.callbacks.CSVLogger(\n",
    "            f\"{model_dir}/training_log.csv\",\n",
    "            append=True\n",
    "        ),\n",
    "        \n",
    "        # TensorBoard\n",
    "        keras.callbacks.TensorBoard(\n",
    "            log_dir=f\"{model_dir}/tensorboard_logs\",\n",
    "            histogram_freq=1,\n",
    "            write_graph=True,\n",
    "            write_images=True\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    return callbacks\n",
    "\n",
    "def train_model(model, train_data, val_data, epochs=100, model_name=\"keypress_model\"):\n",
    "    \"\"\"Train the model with callbacks.\"\"\"\n",
    "    \n",
    "    print(f\"Starting training for {epochs} epochs...\")\n",
    "    print(f\"Model will be saved to: models/{model_name}/\")\n",
    "    \n",
    "    # Create callbacks\n",
    "    callbacks = create_callbacks(model_name)\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        train_data,\n",
    "        validation_data=val_data,\n",
    "        epochs=epochs,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    return history\n",
    "\n",
    "def plot_training_history(history):\n",
    "    \"\"\"Plot training history.\"\"\"\n",
    "    \n",
    "    if not history:\n",
    "        print(\"No training history available\")\n",
    "        return\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Plot training & validation accuracy\n",
    "    axes[0, 0].plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    axes[0, 0].plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    axes[0, 0].set_title('Model Accuracy')\n",
    "    axes[0, 0].set_xlabel('Epoch')\n",
    "    axes[0, 0].set_ylabel('Accuracy')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True)\n",
    "    \n",
    "    # Plot training & validation loss\n",
    "    axes[0, 1].plot(history.history['loss'], label='Training Loss')\n",
    "    axes[0, 1].plot(history.history['val_loss'], label='Validation Loss')\n",
    "    axes[0, 1].set_title('Model Loss')\n",
    "    axes[0, 1].set_xlabel('Epoch')\n",
    "    axes[0, 1].set_ylabel('Loss')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True)\n",
    "    \n",
    "    # Plot precision\n",
    "    if 'precision' in history.history:\n",
    "        axes[1, 0].plot(history.history['precision'], label='Training Precision')\n",
    "        axes[1, 0].plot(history.history['val_precision'], label='Validation Precision')\n",
    "        axes[1, 0].set_title('Model Precision')\n",
    "        axes[1, 0].set_xlabel('Epoch')\n",
    "        axes[1, 0].set_ylabel('Precision')\n",
    "        axes[1, 0].legend()\n",
    "        axes[1, 0].grid(True)\n",
    "    \n",
    "    # Plot recall\n",
    "    if 'recall' in history.history:\n",
    "        axes[1, 1].plot(history.history['recall'], label='Training Recall')\n",
    "        axes[1, 1].plot(history.history['val_recall'], label='Validation Recall')\n",
    "        axes[1, 1].set_title('Model Recall')\n",
    "        axes[1, 1].set_xlabel('Epoch')\n",
    "        axes[1, 1].set_ylabel('Recall')\n",
    "        axes[1, 1].legend()\n",
    "        axes[1, 1].grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Train the model\n",
    "if 'model' in locals() and 'data_splits' in locals():\n",
    "    print(\"Starting model training...\")\n",
    "    \n",
    "    # Create model directory\n",
    "    os.makedirs(\"models\", exist_ok=True)\n",
    "    \n",
    "    # Train the model\n",
    "    history = train_model(\n",
    "        model=model,\n",
    "        train_data=train_gen,\n",
    "        val_data=val_gen,\n",
    "        epochs=50,  # Start with 50 epochs\n",
    "        model_name=\"cnn_lstm_keypress\"\n",
    "    )\n",
    "    \n",
    "    # Plot training history\n",
    "    plot_training_history(history)\n",
    "    \n",
    "    print(\"Training completed!\")\n",
    "    \n",
    "else:\n",
    "    print(\"Model or data not available for training\")\n",
    "    print(\"Please ensure you have:\")\n",
    "    print(\"1. Loaded and preprocessed training data\")\n",
    "    print(\"2. Created the model\")\n",
    "    print(\"3. Prepared data splits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fb7519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Model Performance\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    \"\"\"Evaluate model on test data.\"\"\"\n",
    "    \n",
    "    print(\"Evaluating model on test data...\")\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = model.predict(X_test, verbose=1)\n",
    "    y_pred = np.argmax(predictions, axis=1)\n",
    "    y_true = np.argmax(y_test, axis=1)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "    \n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average='weighted')\n",
    "    recall = recall_score(y_true, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    \n",
    "    print(f\"Test Results:\")\n",
    "    print(f\"  - Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"  - Precision: {precision:.4f}\")\n",
    "    print(f\"  - Recall: {recall:.4f}\")\n",
    "    print(f\"  - F1-Score: {f1:.4f}\")\n",
    "    \n",
    "    return y_pred, y_true, predictions\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, class_names=['Not Pressed', 'Pressed']):\n",
    "    \"\"\"Plot confusion matrix.\"\"\"\n",
    "    \n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.show()\n",
    "    \n",
    "    # Print detailed metrics\n",
    "    print(\"\\nDetailed Classification Report:\")\n",
    "    print(classification_report(y_true, y_pred, target_names=class_names))\n",
    "\n",
    "def plot_prediction_confidence(predictions, y_true, num_samples=100):\n",
    "    \"\"\"Plot prediction confidence distribution.\"\"\"\n",
    "    \n",
    "    # Select random samples\n",
    "    indices = np.random.choice(len(predictions), min(num_samples, len(predictions)), replace=False)\n",
    "    \n",
    "    confidence_scores = np.max(predictions[indices], axis=1)\n",
    "    true_labels = y_true[indices]\n",
    "    \n",
    "    # Separate by correct/incorrect predictions\n",
    "    pred_labels = np.argmax(predictions[indices], axis=1)\n",
    "    correct_mask = (pred_labels == true_labels)\n",
    "    \n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    # Plot confidence for correct predictions\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.hist(confidence_scores[correct_mask], bins=20, alpha=0.7, \n",
    "             color='green', label='Correct Predictions')\n",
    "    plt.hist(confidence_scores[~correct_mask], bins=20, alpha=0.7, \n",
    "             color='red', label='Incorrect Predictions')\n",
    "    plt.xlabel('Prediction Confidence')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Prediction Confidence Distribution')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot confidence by class\n",
    "    plt.subplot(1, 2, 2)\n",
    "    for class_idx in range(2):\n",
    "        class_mask = (true_labels == class_idx)\n",
    "        plt.hist(confidence_scores[class_mask], bins=20, alpha=0.7, \n",
    "                 label=f'Class {class_idx}')\n",
    "    plt.xlabel('Prediction Confidence')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Confidence by True Class')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def analyze_errors(X_test, y_true, y_pred, predictions, num_errors=8):\n",
    "    \"\"\"Analyze prediction errors.\"\"\"\n",
    "    \n",
    "    # Find incorrect predictions\n",
    "    incorrect_indices = np.where(y_true != y_pred)[0]\n",
    "    \n",
    "    if len(incorrect_indices) == 0:\n",
    "        print(\"No prediction errors found!\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Found {len(incorrect_indices)} prediction errors out of {len(y_true)} samples\")\n",
    "    print(f\"Error rate: {len(incorrect_indices)/len(y_true):.2%}\")\n",
    "    \n",
    "    # Show some error cases\n",
    "    num_to_show = min(num_errors, len(incorrect_indices))\n",
    "    error_indices = np.random.choice(incorrect_indices, num_to_show, replace=False)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "    fig.suptitle('Prediction Errors Analysis', fontsize=16)\n",
    "    \n",
    "    for i, idx in enumerate(error_indices):\n",
    "        row = i // 4\n",
    "        col = i % 4\n",
    "        \n",
    "        axes[row, col].imshow(X_test[idx])\n",
    "        \n",
    "        true_label = \"Pressed\" if y_true[idx] == 1 else \"Not Pressed\"\n",
    "        pred_label = \"Pressed\" if y_pred[idx] == 1 else \"Not Pressed\"\n",
    "        confidence = predictions[idx][y_pred[idx]]\n",
    "        \n",
    "        axes[row, col].set_title(f'True: {true_label}\\nPred: {pred_label}\\nConf: {confidence:.3f}')\n",
    "        axes[row, col].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Evaluate the model\n",
    "if 'model' in locals() and 'data_splits' in locals():\n",
    "    # Load best model if available\n",
    "    try:\n",
    "        best_model = keras.models.load_model(\"models/cnn_lstm_keypress/best_model.h5\")\n",
    "        print(\"Loaded best model from checkpoint\")\n",
    "        model = best_model\n",
    "    except:\n",
    "        print(\"Using current model (no checkpoint found)\")\n",
    "    \n",
    "    # Evaluate on test data\n",
    "    y_pred, y_true, predictions = evaluate_model(model, data_splits['X_test'], data_splits['y_test'])\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    plot_confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    # Plot prediction confidence\n",
    "    plot_prediction_confidence(predictions, y_true)\n",
    "    \n",
    "    # Analyze errors\n",
    "    analyze_errors(data_splits['X_test'], y_true, y_pred, predictions)\n",
    "    \n",
    "else:\n",
    "    print(\"Model or data not available for evaluation\")\n",
    "    print(\"Please ensure you have trained the model first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874caa5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real-time Inference Testing\n",
    "def create_inference_pipeline(model, target_key='t', model_path='best_v2.pt'):\n",
    "    \"\"\"Create inference pipeline for real-time testing.\"\"\"\n",
    "    \n",
    "    from ultralytics import YOLO\n",
    "    \n",
    "    # Load YOLO model for key detection\n",
    "    yolo_model = YOLO(model_path)\n",
    "    \n",
    "    def predict_keypress(frame, key_bbox=None):\n",
    "        \"\"\"Predict keypress from a single frame.\"\"\"\n",
    "        \n",
    "        if key_bbox is None:\n",
    "            # Detect key in frame\n",
    "            results = yolo_model(frame)\n",
    "            \n",
    "            for result in results:\n",
    "                if result.boxes is not None:\n",
    "                    for box in result.boxes:\n",
    "                        if result.names[int(box.cls)] == target_key:\n",
    "                            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
    "                            key_bbox = (int(x1), int(y1), int(x2), int(y2))\n",
    "                            break\n",
    "            \n",
    "            if key_bbox is None:\n",
    "                return None, None  # Key not found\n",
    "        \n",
    "        # Extract and preprocess key region\n",
    "        x1, y1, x2, y2 = key_bbox\n",
    "        \n",
    "        # Expand bounding box by 20% (same as video labeler)\n",
    "        width = x2 - x1\n",
    "        height = y2 - y1\n",
    "        expand_x = width * 0.2\n",
    "        expand_y = height * 0.2\n",
    "        \n",
    "        exp_x1 = max(0, int(x1 - expand_x))\n",
    "        exp_y1 = max(0, int(y1 - expand_y))\n",
    "        exp_x2 = min(frame.shape[1], int(x2 + expand_x))\n",
    "        exp_y2 = min(frame.shape[0], int(y2 + expand_y))\n",
    "        \n",
    "        # Extract key region\n",
    "        key_region = frame[exp_y1:exp_y2, exp_x1:exp_x2]\n",
    "        \n",
    "        # Resize to model input size\n",
    "        key_region = cv2.resize(key_region, (64, 64))\n",
    "        \n",
    "        # Normalize\n",
    "        key_region = key_region.astype(np.float32) / 255.0\n",
    "        \n",
    "        # Add batch dimension\n",
    "        key_region = np.expand_dims(key_region, axis=0)\n",
    "        \n",
    "        # Make prediction\n",
    "        prediction = model.predict(key_region, verbose=0)\n",
    "        \n",
    "        # Get probability and class\n",
    "        prob = prediction[0]\n",
    "        predicted_class = np.argmax(prob)\n",
    "        confidence = prob[predicted_class]\n",
    "        \n",
    "        return predicted_class, confidence\n",
    "    \n",
    "    return predict_keypress\n",
    "\n",
    "def test_on_video(video_path, model, target_key='t', output_path=None):\n",
    "    \"\"\"Test model on a video file.\"\"\"\n",
    "    \n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Cannot open video {video_path}\")\n",
    "        return\n",
    "    \n",
    "    # Get video properties\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    print(f\"Video: {video_path}\")\n",
    "    print(f\"FPS: {fps}, Size: {width}x{height}, Frames: {total_frames}\")\n",
    "    \n",
    "    # Create inference pipeline\n",
    "    predict_keypress = create_inference_pipeline(model, target_key)\n",
    "    \n",
    "    # Setup video writer if output path is provided\n",
    "    if output_path:\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "    \n",
    "    # Process video\n",
    "    frame_count = 0\n",
    "    key_bbox = None\n",
    "    predictions = []\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        frame_count += 1\n",
    "        \n",
    "        # Predict keypress\n",
    "        predicted_class, confidence = predict_keypress(frame, key_bbox)\n",
    "        \n",
    "        if predicted_class is not None:\n",
    "            predictions.append({\n",
    "                'frame': frame_count,\n",
    "                'prediction': predicted_class,\n",
    "                'confidence': confidence\n",
    "            })\n",
    "            \n",
    "            # Draw prediction on frame\n",
    "            label = \"PRESSED\" if predicted_class == 1 else \"NOT PRESSED\"\n",
    "            color = (0, 255, 0) if predicted_class == 1 else (0, 0, 255)\n",
    "            \n",
    "            cv2.putText(frame, f\"{label} ({confidence:.3f})\", \n",
    "                       (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)\n",
    "            \n",
    "            # Draw key bounding box if found\n",
    "            if key_bbox:\n",
    "                x1, y1, x2, y2 = key_bbox\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "        \n",
    "        # Write frame to output video\n",
    "        if output_path:\n",
    "            out.write(frame)\n",
    "        \n",
    "        # Display frame (optional)\n",
    "        cv2.imshow('Keypress Detection', frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    # Cleanup\n",
    "    cap.release()\n",
    "    if output_path:\n",
    "        out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    print(f\"Processed {frame_count} frames\")\n",
    "    print(f\"Made {len(predictions)} predictions\")\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "def analyze_video_predictions(predictions):\n",
    "    \"\"\"Analyze predictions from video inference.\"\"\"\n",
    "    \n",
    "    if not predictions:\n",
    "        print(\"No predictions to analyze\")\n",
    "        return\n",
    "    \n",
    "    # Convert to DataFrame for easier analysis\n",
    "    df = pd.DataFrame(predictions)\n",
    "    \n",
    "    # Basic statistics\n",
    "    print(f\"Video Prediction Analysis:\")\n",
    "    print(f\"  - Total frames predicted: {len(df)}\")\n",
    "    print(f\"  - Pressed frames: {sum(df['prediction'] == 1)}\")\n",
    "    print(f\"  - Not pressed frames: {sum(df['prediction'] == 0)}\")\n",
    "    print(f\"  - Average confidence: {df['confidence'].mean():.3f}\")\n",
    "    \n",
    "    # Plot predictions over time\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    \n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(df['frame'], df['prediction'], 'b-', linewidth=2)\n",
    "    plt.title('Key Press Predictions Over Time')\n",
    "    plt.ylabel('Prediction (0=Not Pressed, 1=Pressed)')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(df['frame'], df['confidence'], 'r-', linewidth=2)\n",
    "    plt.title('Prediction Confidence Over Time')\n",
    "    plt.xlabel('Frame Number')\n",
    "    plt.ylabel('Confidence')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Test the model on video\n",
    "if 'model' in locals():\n",
    "    # Example usage (uncomment and modify paths as needed)\n",
    "    \n",
    "    # Test on a video file\n",
    "    # video_path = \"path/to/your/test_video.mp4\"\n",
    "    # output_path = \"keypress_predictions.mp4\"\n",
    "    \n",
    "    # predictions = test_on_video(video_path, model, target_key='t', output_path=output_path)\n",
    "    # analyze_video_predictions(predictions)\n",
    "    \n",
    "    print(\"Real-time inference pipeline created!\")\n",
    "    print(\"To test on a video:\")\n",
    "    print(\"1. Uncomment the lines above\")\n",
    "    print(\"2. Set video_path to your test video\")\n",
    "    print(\"3. Set output_path for result video\")\n",
    "    print(\"4. Run the cell\")\n",
    "    \n",
    "else:\n",
    "    print(\"Model not available for inference testing\")\n",
    "    print(\"Please train the model first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6d60ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Optimization and Fine-tuning\n",
    "def create_optimized_model(input_shape=(64, 64, 3), num_classes=2):\n",
    "    \"\"\"Create optimized CNN model with better architecture.\"\"\"\n",
    "    \n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    \n",
    "    # Initial convolution\n",
    "    x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    # Residual block 1\n",
    "    residual = x\n",
    "    x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Add()([x, residual])\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = layers.Dropout(0.25)(x)\n",
    "    \n",
    "    # Residual block 2\n",
    "    residual = layers.Conv2D(64, (1, 1), padding='same')(x)\n",
    "    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Add()([x, residual])\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = layers.Dropout(0.25)(x)\n",
    "    \n",
    "    # Residual block 3\n",
    "    residual = layers.Conv2D(128, (1, 1), padding='same')(x)\n",
    "    x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Add()([x, residual])\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = layers.Dropout(0.25)(x)\n",
    "    \n",
    "    # Attention mechanism\n",
    "    attention = layers.Conv2D(128, (1, 1), activation='sigmoid')(x)\n",
    "    x = layers.Multiply()([x, attention])\n",
    "    \n",
    "    # Global pooling and dense layers\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dense(512, activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    \n",
    "    x = layers.Dense(256, activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    \n",
    "    # Output layer\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "def fine_tune_model(base_model, X_train, y_train, X_val, y_val, epochs=20):\n",
    "    \"\"\"Fine-tune model with different learning rates.\"\"\"\n",
    "    \n",
    "    print(\"Fine-tuning model...\")\n",
    "    \n",
    "    # Freeze some layers\n",
    "    for layer in base_model.layers[:-4]:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    # Compile with lower learning rate\n",
    "    base_model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    # Create callbacks\n",
    "    callbacks = [\n",
    "        keras.callbacks.EarlyStopping(\n",
    "            monitor='val_accuracy',\n",
    "            patience=10,\n",
    "            restore_best_weights=True\n",
    "        ),\n",
    "        keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=5,\n",
    "            min_lr=1e-7\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    # Fine-tune\n",
    "    history = base_model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=epochs,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    return history\n",
    "\n",
    "def hyperparameter_tuning(X_train, y_train, X_val, y_val):\n",
    "    \"\"\"Perform hyperparameter tuning.\"\"\"\n",
    "    \n",
    "    print(\"Performing hyperparameter tuning...\")\n",
    "    \n",
    "    # Define hyperparameter search space\n",
    "    lr_values = [0.001, 0.0005, 0.0001]\n",
    "    batch_sizes = [16, 32, 64]\n",
    "    dropout_rates = [0.3, 0.5, 0.7]\n",
    "    \n",
    "    best_accuracy = 0\n",
    "    best_params = {}\n",
    "    results = []\n",
    "    \n",
    "    for lr in lr_values:\n",
    "        for batch_size in batch_sizes:\n",
    "            for dropout in dropout_rates:\n",
    "                print(f\"Testing: LR={lr}, Batch={batch_size}, Dropout={dropout}\")\n",
    "                \n",
    "                # Create model with current hyperparameters\n",
    "                model = create_optimized_model()\n",
    "                \n",
    "                # Modify dropout rate\n",
    "                for layer in model.layers:\n",
    "                    if isinstance(layer, layers.Dropout):\n",
    "                        layer.rate = dropout\n",
    "                \n",
    "                # Compile model\n",
    "                model.compile(\n",
    "                    optimizer=keras.optimizers.Adam(learning_rate=lr),\n",
    "                    loss='categorical_crossentropy',\n",
    "                    metrics=['accuracy']\n",
    "                )\n",
    "                \n",
    "                # Train for a few epochs\n",
    "                history = model.fit(\n",
    "                    X_train, y_train,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    epochs=10,\n",
    "                    batch_size=batch_size,\n",
    "                    verbose=0\n",
    "                )\n",
    "                \n",
    "                # Get best validation accuracy\n",
    "                val_accuracy = max(history.history['val_accuracy'])\n",
    "                \n",
    "                results.append({\n",
    "                    'lr': lr,\n",
    "                    'batch_size': batch_size,\n",
    "                    'dropout': dropout,\n",
    "                    'val_accuracy': val_accuracy\n",
    "                })\n",
    "                \n",
    "                if val_accuracy > best_accuracy:\n",
    "                    best_accuracy = val_accuracy\n",
    "                    best_params = {\n",
    "                        'lr': lr,\n",
    "                        'batch_size': batch_size,\n",
    "                        'dropout': dropout\n",
    "                    }\n",
    "                \n",
    "                print(f\"  Validation accuracy: {val_accuracy:.4f}\")\n",
    "    \n",
    "    print(f\"\\nBest parameters: {best_params}\")\n",
    "    print(f\"Best validation accuracy: {best_accuracy:.4f}\")\n",
    "    \n",
    "    return best_params, results\n",
    "\n",
    "def ensemble_prediction(models, X_test):\n",
    "    \"\"\"Create ensemble predictions from multiple models.\"\"\"\n",
    "    \n",
    "    predictions = []\n",
    "    \n",
    "    for model in models:\n",
    "        pred = model.predict(X_test, verbose=0)\n",
    "        predictions.append(pred)\n",
    "    \n",
    "    # Average predictions\n",
    "    ensemble_pred = np.mean(predictions, axis=0)\n",
    "    \n",
    "    return ensemble_pred\n",
    "\n",
    "# Model optimization example\n",
    "if 'data_splits' in locals():\n",
    "    print(\"Starting model optimization...\")\n",
    "    \n",
    "    # Create optimized model\n",
    "    optimized_model = create_optimized_model()\n",
    "    \n",
    "    print(\"Optimized Model Architecture:\")\n",
    "    optimized_model.summary()\n",
    "    \n",
    "    # Compile optimized model\n",
    "    optimized_model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    # Optional: Perform hyperparameter tuning (this will take a while)\n",
    "    # best_params, tuning_results = hyperparameter_tuning(\n",
    "    #     data_splits['X_train'], data_splits['y_train'],\n",
    "    #     data_splits['X_val'], data_splits['y_val']\n",
    "    # )\n",
    "    \n",
    "    print(\"Model optimization setup completed!\")\n",
    "    print(\"Uncomment hyperparameter tuning section to run full optimization\")\n",
    "    \n",
    "else:\n",
    "    print(\"Data not available for model optimization\")\n",
    "    print(\"Please prepare training data first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a199ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export Model for Production\n",
    "def export_model(model, model_name=\"keypress_detector\"):\n",
    "    \"\"\"Export trained model in multiple formats for production.\"\"\"\n",
    "    \n",
    "    # Create export directory\n",
    "    export_dir = f\"exported_models/{model_name}\"\n",
    "    os.makedirs(export_dir, exist_ok=True)\n",
    "    \n",
    "    print(f\"Exporting model to {export_dir}/...\")\n",
    "    \n",
    "    # 1. Save in Keras H5 format\n",
    "    h5_path = f\"{export_dir}/{model_name}.h5\"\n",
    "    model.save(h5_path)\n",
    "    print(f\" Saved H5 model: {h5_path}\")\n",
    "    \n",
    "    # 2. Save in TensorFlow SavedModel format\n",
    "    savedmodel_path = f\"{export_dir}/{model_name}_savedmodel\"\n",
    "    model.save(savedmodel_path)\n",
    "    print(f\" Saved TensorFlow SavedModel: {savedmodel_path}\")\n",
    "    \n",
    "    # 3. Save model weights only\n",
    "    weights_path = f\"{export_dir}/{model_name}_weights.h5\"\n",
    "    model.save_weights(weights_path)\n",
    "    print(f\" Saved model weights: {weights_path}\")\n",
    "    \n",
    "    # 4. Export to TensorFlow Lite for mobile deployment\n",
    "    try:\n",
    "        converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "        converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "        tflite_model = converter.convert()\n",
    "        \n",
    "        tflite_path = f\"{export_dir}/{model_name}.tflite\"\n",
    "        with open(tflite_path, 'wb') as f:\n",
    "            f.write(tflite_model)\n",
    "        print(f\" Saved TensorFlow Lite model: {tflite_path}\")\n",
    "        \n",
    "        # Get model size\n",
    "        model_size = os.path.getsize(tflite_path) / 1024  # KB\n",
    "        print(f\"  TensorFlow Lite model size: {model_size:.1f} KB\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\" TensorFlow Lite export failed: {e}\")\n",
    "    \n",
    "    # 5. Save model architecture as JSON\n",
    "    architecture_path = f\"{export_dir}/{model_name}_architecture.json\"\n",
    "    with open(architecture_path, 'w') as f:\n",
    "        f.write(model.to_json())\n",
    "    print(f\" Saved model architecture: {architecture_path}\")\n",
    "    \n",
    "    # 6. Save model summary\n",
    "    summary_path = f\"{export_dir}/{model_name}_summary.txt\"\n",
    "    with open(summary_path, 'w') as f:\n",
    "        model.summary(print_fn=lambda x: f.write(x + '\\n'))\n",
    "    print(f\" Saved model summary: {summary_path}\")\n",
    "    \n",
    "    return export_dir\n",
    "\n",
    "def create_inference_class(model_path, target_key='t'):\n",
    "    \"\"\"Create a production-ready inference class.\"\"\"\n",
    "    \n",
    "    inference_code = f'''\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "class KeypressDetector:\n",
    "    def __init__(self, model_path=\"{model_path}\", yolo_model_path=\"best_v2.pt\"):\n",
    "        \"\"\"Initialize the keypress detector.\"\"\"\n",
    "        self.model = tf.keras.models.load_model(model_path)\n",
    "        self.yolo_model = YOLO(yolo_model_path)\n",
    "        self.target_key = \"{target_key}\"\n",
    "        self.key_bbox = None\n",
    "        \n",
    "    def detect_key_region(self, frame):\n",
    "        \"\"\"Detect key region in frame using YOLO.\"\"\"\n",
    "        results = self.yolo_model(frame)\n",
    "        \n",
    "        for result in results:\n",
    "            if result.boxes is not None:\n",
    "                for box in result.boxes:\n",
    "                    if result.names[int(box.cls)] == self.target_key:\n",
    "                        x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
    "                        \n",
    "                        # Expand bounding box by 20%\n",
    "                        width = x2 - x1\n",
    "                        height = y2 - y1\n",
    "                        expand_x = width * 0.2\n",
    "                        expand_y = height * 0.2\n",
    "                        \n",
    "                        exp_x1 = max(0, int(x1 - expand_x))\n",
    "                        exp_y1 = max(0, int(y1 - expand_y))\n",
    "                        exp_x2 = min(frame.shape[1], int(x2 + expand_x))\n",
    "                        exp_y2 = min(frame.shape[0], int(y2 + expand_y))\n",
    "                        \n",
    "                        self.key_bbox = (exp_x1, exp_y1, exp_x2, exp_y2)\n",
    "                        return self.key_bbox\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def preprocess_frame(self, frame, bbox=None):\n",
    "        \"\"\"Preprocess frame for model input.\"\"\"\n",
    "        if bbox is None:\n",
    "            bbox = self.key_bbox\n",
    "        \n",
    "        if bbox is None:\n",
    "            return None\n",
    "        \n",
    "        # Extract key region\n",
    "        x1, y1, x2, y2 = bbox\n",
    "        key_region = frame[y1:y2, x1:x2]\n",
    "        \n",
    "        # Resize to model input size\n",
    "        key_region = cv2.resize(key_region, (64, 64))\n",
    "        \n",
    "        # Normalize\n",
    "        key_region = key_region.astype(np.float32) / 255.0\n",
    "        \n",
    "        # Add batch dimension\n",
    "        key_region = np.expand_dims(key_region, axis=0)\n",
    "        \n",
    "        return key_region\n",
    "    \n",
    "    def predict(self, frame, bbox=None):\n",
    "        \"\"\"Predict keypress from frame.\"\"\"\n",
    "        # Preprocess frame\n",
    "        input_data = self.preprocess_frame(frame, bbox)\n",
    "        \n",
    "        if input_data is None:\n",
    "            return None, None\n",
    "        \n",
    "        # Make prediction\n",
    "        prediction = self.model.predict(input_data, verbose=0)\n",
    "        \n",
    "        # Get result\n",
    "        prob = prediction[0]\n",
    "        predicted_class = np.argmax(prob)\n",
    "        confidence = prob[predicted_class]\n",
    "        \n",
    "        return predicted_class, confidence\n",
    "    \n",
    "    def process_video(self, video_path, output_path=None):\n",
    "        \"\"\"Process entire video and return predictions.\"\"\"\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        \n",
    "        if not cap.isOpened():\n",
    "            raise ValueError(f\"Cannot open video: {{video_path}}\")\n",
    "        \n",
    "        # Get video properties\n",
    "        fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        \n",
    "        # Setup video writer if output path provided\n",
    "        if output_path:\n",
    "            fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "            out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "        \n",
    "        predictions = []\n",
    "        frame_count = 0\n",
    "        \n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            frame_count += 1\n",
    "            \n",
    "            # Detect key region on first frame\n",
    "            if self.key_bbox is None:\n",
    "                self.detect_key_region(frame)\n",
    "            \n",
    "            # Make prediction\n",
    "            predicted_class, confidence = self.predict(frame)\n",
    "            \n",
    "            if predicted_class is not None:\n",
    "                predictions.append({{\n",
    "                    'frame': frame_count,\n",
    "                    'prediction': predicted_class,\n",
    "                    'confidence': confidence\n",
    "                }})\n",
    "                \n",
    "                # Draw prediction on frame\n",
    "                label = \"PRESSED\" if predicted_class == 1 else \"NOT PRESSED\"\n",
    "                color = (0, 255, 0) if predicted_class == 1 else (0, 0, 255)\n",
    "                \n",
    "                cv2.putText(frame, f\"{{label}} ({{confidence:.3f}})\", \n",
    "                           (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)\n",
    "                \n",
    "                # Draw bounding box\n",
    "                if self.key_bbox:\n",
    "                    x1, y1, x2, y2 = self.key_bbox\n",
    "                    cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "            \n",
    "            # Write frame to output\n",
    "            if output_path:\n",
    "                out.write(frame)\n",
    "        \n",
    "        # Cleanup\n",
    "        cap.release()\n",
    "        if output_path:\n",
    "            out.release()\n",
    "        \n",
    "        return predictions\n",
    "\n",
    "# Example usage:\n",
    "# detector = KeypressDetector()\n",
    "# predictions = detector.process_video(\"input_video.mp4\", \"output_video.mp4\")\n",
    "'''\n",
    "    \n",
    "    return inference_code\n",
    "\n",
    "def save_inference_code(code, export_dir):\n",
    "    \"\"\"Save inference code to file.\"\"\"\n",
    "    code_path = f\"{export_dir}/keypress_detector.py\"\n",
    "    with open(code_path, 'w') as f:\n",
    "        f.write(code)\n",
    "    print(f\" Saved inference code: {code_path}\")\n",
    "    return code_path\n",
    "\n",
    "def create_deployment_requirements():\n",
    "    \"\"\"Create requirements.txt for deployment.\"\"\"\n",
    "    requirements = '''\n",
    "tensorflow>=2.8.0\n",
    "opencv-python>=4.5.0\n",
    "ultralytics>=8.0.0\n",
    "numpy>=1.20.0\n",
    "'''\n",
    "    return requirements\n",
    "\n",
    "def save_deployment_files(export_dir):\n",
    "    \"\"\"Save deployment files.\"\"\"\n",
    "    \n",
    "    # Save requirements.txt\n",
    "    requirements_path = f\"{export_dir}/requirements.txt\"\n",
    "    with open(requirements_path, 'w') as f:\n",
    "        f.write(create_deployment_requirements())\n",
    "    print(f\" Saved requirements: {requirements_path}\")\n",
    "    \n",
    "    # Save README\n",
    "    readme_content = f'''\n",
    "# Keypress Detection Model\n",
    "\n",
    "This directory contains the trained keypress detection model and inference code.\n",
    "\n",
    "## Files:\n",
    "- `keypress_detector.h5`: Trained Keras model\n",
    "- `keypress_detector_savedmodel/`: TensorFlow SavedModel format\n",
    "- `keypress_detector.tflite`: TensorFlow Lite model for mobile\n",
    "- `keypress_detector.py`: Inference class for production use\n",
    "- `requirements.txt`: Required Python packages\n",
    "\n",
    "## Usage:\n",
    "```python\n",
    "from keypress_detector import KeypressDetector\n",
    "\n",
    "# Initialize detector\n",
    "detector = KeypressDetector(\"keypress_detector.h5\")\n",
    "\n",
    "# Process video\n",
    "predictions = detector.process_video(\"input.mp4\", \"output.mp4\")\n",
    "```\n",
    "\n",
    "## Installation:\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "Generated on: {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}\n",
    "'''\n",
    "    \n",
    "    readme_path = f\"{export_dir}/README.md\"\n",
    "    with open(readme_path, 'w') as f:\n",
    "        f.write(readme_content)\n",
    "    print(f\" Saved README: {readme_path}\")\n",
    "\n",
    "# Export the model for production\n",
    "if 'model' in locals():\n",
    "    # Export model\n",
    "    export_dir = export_model(model, \"keypress_detector\")\n",
    "    \n",
    "    # Create inference code\n",
    "    model_path = f\"{export_dir}/keypress_detector.h5\"\n",
    "    inference_code = create_inference_class(model_path)\n",
    "    save_inference_code(inference_code, export_dir)\n",
    "    \n",
    "    # Save deployment files\n",
    "    save_deployment_files(export_dir)\n",
    "    \n",
    "    print(f\"\\n Model successfully exported to: {export_dir}\")\n",
    "    print(\"\\nProduction-ready files created:\")\n",
    "    print(\"- Model files (H5, SavedModel, TensorFlow Lite)\")\n",
    "    print(\"- Inference code (keypress_detector.py)\")\n",
    "    print(\"- Requirements and documentation\")\n",
    "    print(\"\\nYour model is ready for deployment!\")\n",
    "    \n",
    "else:\n",
    "    print(\"Model not available for export\")\n",
    "    print(\"Please train the model first\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
