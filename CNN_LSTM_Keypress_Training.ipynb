{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5aea25be",
   "metadata": {},
   "source": [
    "# Multiple Deep Learning Models for Key Press Detection\n",
    "\n",
    "This notebook implements and compares multiple deep learning architectures for key press detection from video sequences using PyTorch:\n",
    "\n",
    "## Available Models:\n",
    "1. **CNN Model**: Pure convolutional neural network for single frame classification\n",
    "2. **LSTM Model**: Sequential model using LSTM for temporal pattern recognition\n",
    "3. **CNN+LSTM Model**: Combined architecture with CNN feature extraction + LSTM temporal modeling\n",
    "4. **ResNet Model**: Residual network for robust feature extraction\n",
    "5. **Transformer Model**: Attention-based model for sequence modeling\n",
    "\n",
    "## Dataset Structure\n",
    "The training data comes from the video labeler application with the following format:\n",
    "- Image sequences (64x64x3) of key regions\n",
    "- Binary labels (0: not pressed, 1: pressed)\n",
    "- Temporal ordering for sequence modeling\n",
    "\n",
    "## Training Scenarios\n",
    "- **Single Frame Classification**: CNN, ResNet models\n",
    "- **Sequence Classification**: LSTM, CNN+LSTM, Transformer models\n",
    "- **Comparison Study**: Performance analysis across all models\n",
    "\n",
    "## Framework\n",
    "- **PyTorch**: Deep learning framework\n",
    "- **PyTorch Lightning**: Training framework for clean, scalable code\n",
    "- **Weights & Biases**: Experiment tracking and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9c41b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet18, resnet34\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Optional: PyTorch Lightning for clean training code\n",
    "try:\n",
    "    import pytorch_lightning as pl\n",
    "    from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "    from pytorch_lightning.loggers import WandbLogger\n",
    "    LIGHTNING_AVAILABLE = True\n",
    "    print(\"✓ PyTorch Lightning available\")\n",
    "except ImportError:\n",
    "    LIGHTNING_AVAILABLE = False\n",
    "    print(\"⚠ PyTorch Lightning not available - using basic PyTorch training\")\n",
    "\n",
    "# Optional: Weights & Biases for experiment tracking\n",
    "try:\n",
    "    import wandb\n",
    "    WANDB_AVAILABLE = True\n",
    "    print(\"✓ Weights & Biases available\")\n",
    "except ImportError:\n",
    "    WANDB_AVAILABLE = False\n",
    "    print(\"⚠ Weights & Biases not available - using local logging\")\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"Device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1559207a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and Preprocess Training Data\n",
    "class KeypressDataset(Dataset):\n",
    "    \"\"\"PyTorch Dataset for keypress detection.\"\"\"\n",
    "    \n",
    "    def __init__(self, images, labels, transform=None, sequence_length=None):\n",
    "        self.images = torch.FloatTensor(images)\n",
    "        \n",
    "        # Check if labels are already one-hot encoded\n",
    "        if len(labels.shape) > 1 and labels.shape[1] > 1:\n",
    "            # Already one-hot encoded - use as is\n",
    "            self.labels = torch.FloatTensor(labels)\n",
    "            print(f\"Using one-hot encoded labels of shape {self.labels.shape}\")\n",
    "        else:\n",
    "            # Convert to LongTensor for class indices\n",
    "            self.labels = torch.LongTensor(labels)\n",
    "            print(f\"Using class index labels of shape {self.labels.shape}\")\n",
    "        \n",
    "        self.transform = transform\n",
    "        self.sequence_length = sequence_length\n",
    "        \n",
    "        # Create sequences if sequence_length is provided\n",
    "        if sequence_length is not None:\n",
    "            self.create_sequences()\n",
    "    \n",
    "    def create_sequences(self):\n",
    "        \"\"\"Create sequences for temporal models.\"\"\"\n",
    "        sequences = []\n",
    "        seq_labels = []\n",
    "        \n",
    "        for i in range(len(self.images) - self.sequence_length + 1):\n",
    "            seq = self.images[i:i + self.sequence_length]\n",
    "            label = self.labels[i + self.sequence_length - 1]  # Use last frame's label\n",
    "            sequences.append(seq)\n",
    "            seq_labels.append(label)\n",
    "        \n",
    "        self.images = torch.stack(sequences)\n",
    "        self.labels = torch.stack(seq_labels)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            if self.sequence_length is not None:\n",
    "                # Apply transform to each frame in sequence\n",
    "                transformed_seq = []\n",
    "                for frame in image:\n",
    "                    transformed_seq.append(self.transform(frame))\n",
    "                image = torch.stack(transformed_seq)\n",
    "            else:\n",
    "                image = self.transform(image)\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "def load_training_data(data_dir=\"labeled_data\"):\n",
    "    \"\"\"Load training data from JSON files exported by video labeler.\"\"\"\n",
    "    \n",
    "    # Find all training data files\n",
    "    json_files = glob.glob(os.path.join(data_dir, \"training_data_*.json\"))\n",
    "    \n",
    "    if not json_files:\n",
    "        raise FileNotFoundError(f\"No training data found in {data_dir}\")\n",
    "    \n",
    "    all_images = []\n",
    "    all_labels = []\n",
    "    all_frame_indices = []\n",
    "    \n",
    "    print(f\"Found {len(json_files)} training data files:\")\n",
    "    \n",
    "    for json_file in json_files:\n",
    "        print(f\"Loading: {json_file}\")\n",
    "        \n",
    "        with open(json_file, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        # Extract sequence data\n",
    "        sequence_data = data['sequence_data']\n",
    "        \n",
    "        for item in sequence_data:\n",
    "            # Convert image list back to numpy array\n",
    "            image = np.array(item['image'], dtype=np.float32)\n",
    "            \n",
    "            # Ensure image is in correct format (64, 64, 3)\n",
    "            if image.shape != (64, 64, 3):\n",
    "                print(f\"Warning: Invalid image shape {image.shape}, skipping...\")\n",
    "                continue\n",
    "            \n",
    "            # Convert to PyTorch format (C, H, W)\n",
    "            image = np.transpose(image, (2, 0, 1))\n",
    "            all_images.append(image)\n",
    "            all_labels.append(item['label'])\n",
    "            all_frame_indices.append(item['frame_idx'])\n",
    "        \n",
    "        print(f\"  - Loaded {len(sequence_data)} samples\")\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    X = np.array(all_images)\n",
    "    y = np.array(all_labels)\n",
    "    frame_indices = np.array(all_frame_indices)\n",
    "    \n",
    "    print(f\"\\nTotal dataset:\")\n",
    "    print(f\"  - Images shape: {X.shape}\")\n",
    "    print(f\"  - Labels shape: {y.shape}\")\n",
    "    print(f\"  - Label distribution: {np.bincount(y)}\")\n",
    "    \n",
    "    return X, y, frame_indices\n",
    "\n",
    "def create_data_transforms():\n",
    "    \"\"\"Create data transforms for training and validation.\"\"\"\n",
    "    \n",
    "    # Training transforms (with augmentation)\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.RandomHorizontalFlip(p=0.1),  # Low probability for text\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.1),\n",
    "        transforms.RandomErasing(p=0.1, scale=(0.02, 0.1)),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    # Validation transforms (no augmentation)\n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    return train_transform, val_transform\n",
    "\n",
    "# Load the data\n",
    "try:\n",
    "    X, y, frame_indices = load_training_data()\n",
    "    print(\"Data loaded successfully!\")\n",
    "    \n",
    "    # Create transforms\n",
    "    train_transform, val_transform = create_data_transforms()\n",
    "    print(\"Data transforms created!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error loading data: {e}\")\n",
    "    print(\"Please make sure you have exported training data from the video labeler.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b197740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Exploration and Visualization\n",
    "def visualize_dataset(X, y, frame_indices, num_samples=8):\n",
    "    \"\"\"Visualize sample images and analyze dataset.\"\"\"\n",
    "    \n",
    "    if len(X) == 0:\n",
    "        print(\"No data to visualize\")\n",
    "        return\n",
    "    \n",
    "    # Plot sample images\n",
    "    fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "    fig.suptitle('Sample Key Region Images', fontsize=16)\n",
    "    \n",
    "    # Show samples from each class\n",
    "    pressed_indices = np.where(y == 1)[0]\n",
    "    not_pressed_indices = np.where(y == 0)[0]\n",
    "    \n",
    "    for i in range(4):\n",
    "        # Not pressed samples\n",
    "        if i < len(not_pressed_indices):\n",
    "            idx = not_pressed_indices[i]\n",
    "            # Ensure image is in proper format for matplotlib\n",
    "            img = X[idx].copy()\n",
    "            # Convert from channels-first (3, 64, 64) to channels-last (64, 64, 3)\n",
    "            img = np.transpose(img, (1, 2, 0))\n",
    "            if img.max() <= 1.0:  # If normalized to [0,1]\n",
    "                img = (img * 255).astype(np.uint8)\n",
    "            elif img.min() < 0:  # If normalized to [-1,1]\n",
    "                img = ((img + 1) * 127.5).astype(np.uint8)\n",
    "            axes[0, i].imshow(img)\n",
    "            axes[0, i].set_title(f'Not Pressed (Frame {frame_indices[idx]})')\n",
    "            axes[0, i].axis('off')\n",
    "        \n",
    "        # Pressed samples\n",
    "        if i < len(pressed_indices):\n",
    "            idx = pressed_indices[i]\n",
    "            # Ensure image is in proper format for matplotlib\n",
    "            img = X[idx].copy()\n",
    "            # Convert from channels-first (3, 64, 64) to channels-last (64, 64, 3)\n",
    "            img = np.transpose(img, (1, 2, 0))\n",
    "            if img.max() <= 1.0:  # If normalized to [0,1]\n",
    "                img = (img * 255).astype(np.uint8)\n",
    "            elif img.min() < 0:  # If normalized to [-1,1]\n",
    "                img = ((img + 1) * 127.5).astype(np.uint8)\n",
    "            axes[1, i].imshow(img)\n",
    "            axes[1, i].set_title(f'Pressed (Frame {frame_indices[idx]})')\n",
    "            axes[1, i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Label distribution\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    labels_count = np.bincount(y)\n",
    "    plt.bar(['Not Pressed', 'Pressed'], labels_count, \n",
    "            color=['lightcoral', 'lightgreen'])\n",
    "    plt.title('Label Distribution')\n",
    "    plt.ylabel('Count')\n",
    "    \n",
    "    # Add percentage labels\n",
    "    total = len(y)\n",
    "    for i, count in enumerate(labels_count):\n",
    "        plt.text(i, count + total*0.01, f'{count}\\n({count/total:.1%})', \n",
    "                ha='center', va='bottom')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.hist(frame_indices, bins=50, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "    plt.title('Frame Index Distribution')\n",
    "    plt.xlabel('Frame Index')\n",
    "    plt.ylabel('Frequency')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Dataset statistics\n",
    "    print(f\"Dataset Statistics:\")\n",
    "    print(f\"  - Total samples: {len(X)}\")\n",
    "    print(f\"  - Image shape: {X.shape[1:]}\")\n",
    "    print(f\"  - Image value range: [{X.min():.3f}, {X.max():.3f}]\")\n",
    "    print(f\"  - Not pressed samples: {labels_count[0]} ({labels_count[0]/total:.1%})\")\n",
    "    print(f\"  - Pressed samples: {labels_count[1]} ({labels_count[1]/total:.1%})\")\n",
    "\n",
    "# Visualize the dataset\n",
    "if 'X' in locals() and len(X) > 0:\n",
    "    visualize_dataset(X, y, frame_indices)\n",
    "else:\n",
    "    print(\"No data available for visualization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc0229e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation and Preprocessing\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def create_data_augmentation():\n",
    "    \"\"\"Create data augmentation pipeline.\"\"\"\n",
    "    \n",
    "    # Define augmentation parameters\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=10,          # Random rotation\n",
    "        width_shift_range=0.1,      # Random horizontal shift\n",
    "        height_shift_range=0.1,     # Random vertical shift\n",
    "        brightness_range=[0.8, 1.2], # Random brightness\n",
    "        zoom_range=0.1,             # Random zoom\n",
    "        horizontal_flip=False,       # No horizontal flip (text orientation)\n",
    "        fill_mode='nearest',        # Fill mode for transformations\n",
    "        rescale=None               # Don't rescale (already normalized)\n",
    "    )\n",
    "    \n",
    "    return datagen\n",
    "\n",
    "def augment_dataset(X, y, augment_factor=2):\n",
    "    \"\"\"Augment dataset to increase sample size.\"\"\"\n",
    "    \n",
    "    if len(X) == 0:\n",
    "        return X, y\n",
    "    \n",
    "    print(f\"Original dataset size: {len(X)}\")\n",
    "    \n",
    "    # Separate classes\n",
    "    pressed_indices = np.where(y == 1)[0]\n",
    "    not_pressed_indices = np.where(y == 0)[0]\n",
    "    \n",
    "    # Balance classes by augmenting minority class\n",
    "    if len(pressed_indices) < len(not_pressed_indices):\n",
    "        minority_class = 1\n",
    "        minority_indices = pressed_indices\n",
    "        majority_indices = not_pressed_indices\n",
    "    else:\n",
    "        minority_class = 0\n",
    "        minority_indices = not_pressed_indices\n",
    "        majority_indices = pressed_indices\n",
    "    \n",
    "    print(f\"Minority class: {minority_class} ({len(minority_indices)} samples)\")\n",
    "    print(f\"Majority class: {1-minority_class} ({len(majority_indices)} samples)\")\n",
    "    \n",
    "    # Create augmentation generator\n",
    "    datagen = create_data_augmentation()\n",
    "    \n",
    "    # Augment minority class\n",
    "    X_minority = X[minority_indices]\n",
    "    y_minority = y[minority_indices]\n",
    "    \n",
    "    # Generate augmented samples\n",
    "    augmented_X = []\n",
    "    augmented_y = []\n",
    "    \n",
    "    target_size = len(majority_indices)\n",
    "    samples_needed = target_size - len(minority_indices)\n",
    "    \n",
    "    if samples_needed > 0:\n",
    "        samples_per_original = samples_needed // len(minority_indices) + 1\n",
    "        \n",
    "        for i, (img, label) in enumerate(zip(X_minority, y_minority)):\n",
    "            # Add original sample\n",
    "            augmented_X.append(img)\n",
    "            augmented_y.append(label)\n",
    "            \n",
    "            # Convert from PyTorch format (C, H, W) to Keras format (H, W, C)\n",
    "            # Make sure we transpose the correct dimensions\n",
    "            if img.shape[0] == 3 and img.shape[1] == 64 and img.shape[2] == 64:\n",
    "                img_keras = np.transpose(img, (1, 2, 0))\n",
    "            else:\n",
    "                # If the image is not in the expected format, print an error message\n",
    "                print(f\"Unexpected image shape: {img.shape}, skipping augmentation for this sample\")\n",
    "                continue\n",
    "                \n",
    "            # Generate augmented samples\n",
    "            img_batch = np.expand_dims(img_keras, axis=0)\n",
    "            aug_iter = datagen.flow(img_batch, batch_size=1, shuffle=False)\n",
    "            \n",
    "            for _ in range(samples_per_original):\n",
    "                if len(augmented_X) >= target_size:\n",
    "                    break\n",
    "                aug_img_keras = next(aug_iter)[0]\n",
    "                \n",
    "                # Convert back to PyTorch format (C, H, W)\n",
    "                aug_img = np.transpose(aug_img_keras, (2, 0, 1))\n",
    "                \n",
    "                augmented_X.append(aug_img)\n",
    "                augmented_y.append(label)\n",
    "    \n",
    "    # Combine original majority class with augmented minority class\n",
    "    X_balanced = np.concatenate([X[majority_indices], np.array(augmented_X[:samples_needed])])\n",
    "    y_balanced = np.concatenate([y[majority_indices], np.array(augmented_y[:samples_needed])])\n",
    "    \n",
    "    # Shuffle the balanced dataset\n",
    "    shuffle_indices = np.random.permutation(len(X_balanced))\n",
    "    X_balanced = X_balanced[shuffle_indices]\n",
    "    y_balanced = y_balanced[shuffle_indices]\n",
    "    \n",
    "    print(f\"Balanced dataset size: {len(X_balanced)}\")\n",
    "    print(f\"New class distribution: {np.bincount(y_balanced)}\")\n",
    "    \n",
    "    return X_balanced, y_balanced\n",
    "\n",
    "def preprocess_data(X, y, balance_classes=True):\n",
    "    \"\"\"Preprocess data for training.\"\"\"\n",
    "    \n",
    "    if len(X) == 0:\n",
    "        return X, y\n",
    "    \n",
    "    # Ensure data is in correct format\n",
    "    X = np.array(X, dtype=np.float32)\n",
    "    y = np.array(y, dtype=np.int32)\n",
    "    \n",
    "    # Print shape information for debugging\n",
    "    print(f\"Input X shape: {X.shape}\")\n",
    "    print(f\"Expected format: (N, 3, 64, 64) - channels first\")\n",
    "    \n",
    "    # Clip values to [0, 1] range (should already be normalized)\n",
    "    X = np.clip(X, 0.0, 1.0)\n",
    "    \n",
    "    # Balance classes if requested\n",
    "    if balance_classes:\n",
    "        X, y = augment_dataset(X, y)\n",
    "    \n",
    "    # Convert labels to categorical\n",
    "    y_categorical = np.eye(2)[y]  # One-hot encoding without keras dependency\n",
    "    \n",
    "    print(f\"Preprocessed dataset:\")\n",
    "    print(f\"  - X shape: {X.shape}\")\n",
    "    print(f\"  - y shape: {y_categorical.shape}\")\n",
    "    print(f\"  - X range: [{X.min():.3f}, {X.max():.3f}]\")\n",
    "    \n",
    "    return X, y_categorical\n",
    "\n",
    "# Preprocess the data\n",
    "if 'X' in locals() and len(X) > 0:\n",
    "    X_processed, y_processed = preprocess_data(X, y)\n",
    "    print(\"Data preprocessing completed!\")\n",
    "else:\n",
    "    print(\"No data available for preprocessing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b31f0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple Model Architectures\n",
    "class CNNModel(nn.Module):\n",
    "    \"\"\"Pure CNN model for single frame classification.\"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes=2):\n",
    "        super(CNNModel, self).__init__()\n",
    "        \n",
    "        # Feature extraction layers\n",
    "        self.features = nn.Sequential(\n",
    "            # First conv block\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout2d(0.25),\n",
    "            \n",
    "            # Second conv block\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout2d(0.25),\n",
    "            \n",
    "            # Third conv block\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout2d(0.25),\n",
    "            \n",
    "            # Global average pooling\n",
    "            nn.AdaptiveAvgPool2d((1, 1))\n",
    "        )\n",
    "        \n",
    "        # Classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    \"\"\"LSTM model for sequence classification.\"\"\"\n",
    "    \n",
    "    def __init__(self, input_size=64*64*3, hidden_size=128, num_layers=2, num_classes=2):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # LSTM layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, \n",
    "                           batch_first=True, dropout=0.3, bidirectional=True)\n",
    "        \n",
    "        # Classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_size * 2, 256),  # *2 for bidirectional\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Reshape for LSTM (batch, seq_len, features)\n",
    "        batch_size, seq_len, c, h, w = x.shape\n",
    "        x = x.view(batch_size, seq_len, -1)\n",
    "        \n",
    "        # LSTM forward pass\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        \n",
    "        # Use last output\n",
    "        x = lstm_out[:, -1, :]\n",
    "        \n",
    "        # Classifier\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "class CNNLSTMModel(nn.Module):\n",
    "    \"\"\"CNN+LSTM model combining spatial and temporal features.\"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes=2):\n",
    "        super(CNNLSTMModel, self).__init__()\n",
    "        \n",
    "        # CNN feature extractor\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.AdaptiveAvgPool2d((1, 1))\n",
    "        )\n",
    "        \n",
    "        # LSTM for temporal modeling\n",
    "        self.lstm = nn.LSTM(128, 64, num_layers=2, \n",
    "                           batch_first=True, dropout=0.3, bidirectional=True)\n",
    "        \n",
    "        # Classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(64 * 2, 128),  # *2 for bidirectional\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len, c, h, w = x.shape\n",
    "        \n",
    "        # Extract CNN features for each frame\n",
    "        cnn_features = []\n",
    "        for i in range(seq_len):\n",
    "            frame_features = self.cnn(x[:, i, :, :, :])\n",
    "            frame_features = frame_features.view(batch_size, -1)\n",
    "            cnn_features.append(frame_features)\n",
    "        \n",
    "        # Stack features for LSTM\n",
    "        cnn_features = torch.stack(cnn_features, dim=1)\n",
    "        \n",
    "        # LSTM forward pass\n",
    "        lstm_out, _ = self.lstm(cnn_features)\n",
    "        \n",
    "        # Use last output\n",
    "        x = lstm_out[:, -1, :]\n",
    "        \n",
    "        # Classifier\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "class ResNetModel(nn.Module):\n",
    "    \"\"\"ResNet model for robust feature extraction.\"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes=2, pretrained=True):\n",
    "        super(ResNetModel, self).__init__()\n",
    "        \n",
    "        # Load pretrained ResNet\n",
    "        self.backbone = resnet18(pretrained=pretrained)\n",
    "        \n",
    "        # Replace final layer\n",
    "        self.backbone.fc = nn.Sequential(\n",
    "            nn.Linear(self.backbone.fc.in_features, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "    \"\"\"Transformer model for sequence classification.\"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes=2, d_model=256, nhead=8, num_layers=4):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        \n",
    "        # CNN feature extractor\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.AdaptiveAvgPool2d((1, 1))\n",
    "        )\n",
    "        \n",
    "        # Projection to d_model\n",
    "        self.projection = nn.Linear(128, d_model)\n",
    "        \n",
    "        # Positional encoding\n",
    "        self.pos_encoding = nn.Parameter(torch.randn(1000, d_model))\n",
    "        \n",
    "        # Transformer encoder\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model, nhead=nhead, dim_feedforward=d_model*4, \n",
    "            dropout=0.1, batch_first=True\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        \n",
    "        # Classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(d_model, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len, c, h, w = x.shape\n",
    "        \n",
    "        # Extract features for each frame\n",
    "        features = []\n",
    "        for i in range(seq_len):\n",
    "            frame_features = self.feature_extractor(x[:, i, :, :, :])\n",
    "            frame_features = frame_features.view(batch_size, -1)\n",
    "            features.append(frame_features)\n",
    "        \n",
    "        # Stack and project features\n",
    "        features = torch.stack(features, dim=1)\n",
    "        features = self.projection(features)\n",
    "        \n",
    "        # Add positional encoding\n",
    "        features = features + self.pos_encoding[:seq_len, :].unsqueeze(0)\n",
    "        \n",
    "        # Transformer forward pass\n",
    "        transformer_out = self.transformer(features)\n",
    "        \n",
    "        # Use last output\n",
    "        x = transformer_out[:, -1, :]\n",
    "        \n",
    "        # Classifier\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# Model factory function\n",
    "def create_model(model_type, num_classes=2, **kwargs):\n",
    "    \"\"\"Create model based on type.\"\"\"\n",
    "    \n",
    "    models = {\n",
    "        'cnn': CNNModel,\n",
    "        'lstm': LSTMModel,\n",
    "        'cnn_lstm': CNNLSTMModel,\n",
    "        'resnet': ResNetModel,\n",
    "        'transformer': TransformerModel\n",
    "    }\n",
    "    \n",
    "    if model_type not in models:\n",
    "        raise ValueError(f\"Unknown model type: {model_type}\")\n",
    "    \n",
    "    model = models[model_type](num_classes=num_classes, **kwargs)\n",
    "    return model\n",
    "\n",
    "# Display model information\n",
    "print(\"Available models:\")\n",
    "for model_type in ['cnn', 'lstm', 'cnn_lstm', 'resnet', 'transformer']:\n",
    "    model = create_model(model_type)\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"  {model_type.upper()}: {total_params:,} total params, {trainable_params:,} trainable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20590404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Pipeline for Multiple Models\n",
    "class ModelTrainer:\n",
    "    \"\"\"Unified training pipeline for all models.\"\"\"\n",
    "    \n",
    "    def __init__(self, model, device='cuda', learning_rate=0.001):\n",
    "        self.model = model.to(device)\n",
    "        self.device = device\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        # Loss function and optimizer\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            self.optimizer, mode='min', factor=0.5, patience=7, verbose=True\n",
    "        )\n",
    "        \n",
    "        # Training history\n",
    "        self.history = {\n",
    "            'train_loss': [], 'train_acc': [],\n",
    "            'val_loss': [], 'val_acc': [],\n",
    "            'learning_rate': []\n",
    "        }\n",
    "    \n",
    "    def train_epoch(self, train_loader):\n",
    "        \"\"\"Train for one epoch.\"\"\"\n",
    "        self.model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data, target = data.to(self.device), target.to(self.device)\n",
    "            \n",
    "            # Handle target format - check if one-hot encoded or class indices\n",
    "            if len(target.shape) > 1 and target.shape[1] > 1:\n",
    "                # One-hot encoded - get the class indices\n",
    "                _, target_indices = torch.max(target, 1)\n",
    "            else:\n",
    "                # Already class indices\n",
    "                target_indices = target\n",
    "            \n",
    "            # Zero gradients\n",
    "            self.optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            output = self.model(data)\n",
    "            loss = self.criterion(output, target_indices)\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            # Statistics\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            total += target_indices.size(0)\n",
    "            correct += (predicted == target_indices).sum().item()\n",
    "            \n",
    "            if batch_idx % 10 == 0:\n",
    "                print(f'Batch {batch_idx}/{len(train_loader)}, '\n",
    "                      f'Loss: {loss.item():.4f}, '\n",
    "                      f'Acc: {100.*correct/total:.2f}%')\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        epoch_acc = 100. * correct / total\n",
    "        \n",
    "        return epoch_loss, epoch_acc\n",
    "    \n",
    "    def validate_epoch(self, val_loader):\n",
    "        \"\"\"Validate for one epoch.\"\"\"\n",
    "        self.model.eval()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for data, target in val_loader:\n",
    "                data, target = data.to(self.device), target.to(self.device)\n",
    "                \n",
    "                # Handle target format - check if one-hot encoded or class indices\n",
    "                if len(target.shape) > 1 and target.shape[1] > 1:\n",
    "                    # One-hot encoded - get the class indices\n",
    "                    _, target_indices = torch.max(target, 1)\n",
    "                else:\n",
    "                    # Already class indices\n",
    "                    target_indices = target\n",
    "                \n",
    "                output = self.model(data)\n",
    "                loss = self.criterion(output, target_indices)\n",
    "                \n",
    "                running_loss += loss.item()\n",
    "                _, predicted = torch.max(output.data, 1)\n",
    "                total += target_indices.size(0)\n",
    "                correct += (predicted == target_indices).sum().item()\n",
    "        \n",
    "        epoch_loss = running_loss / len(val_loader)\n",
    "        epoch_acc = 100. * correct / total\n",
    "        \n",
    "        return epoch_loss, epoch_acc\n",
    "    \n",
    "    def train(self, train_loader, val_loader, epochs=50, early_stopping_patience=15):\n",
    "        \"\"\"Train the model.\"\"\"\n",
    "        best_val_loss = float('inf')\n",
    "        patience_counter = 0\n",
    "        \n",
    "        print(f\"Training for {epochs} epochs...\")\n",
    "        print(f\"Model: {self.model.__class__.__name__}\")\n",
    "        print(f\"Device: {self.device}\")\n",
    "        print(f\"Learning rate: {self.learning_rate}\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            print(f'\\nEpoch {epoch+1}/{epochs}')\n",
    "            print('-' * 20)\n",
    "            \n",
    "            # Training\n",
    "            train_loss, train_acc = self.train_epoch(train_loader)\n",
    "            \n",
    "            # Validation\n",
    "            val_loss, val_acc = self.validate_epoch(val_loader)\n",
    "            \n",
    "            # Learning rate scheduling\n",
    "            self.scheduler.step(val_loss)\n",
    "            current_lr = self.optimizer.param_groups[0]['lr']\n",
    "            \n",
    "            # Save history\n",
    "            self.history['train_loss'].append(train_loss)\n",
    "            self.history['train_acc'].append(train_acc)\n",
    "            self.history['val_loss'].append(val_loss)\n",
    "            self.history['val_acc'].append(val_acc)\n",
    "            self.history['learning_rate'].append(current_lr)\n",
    "            \n",
    "            print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%')\n",
    "            print(f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%')\n",
    "            print(f'Learning Rate: {current_lr:.6f}')\n",
    "            \n",
    "            # Early stopping\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                patience_counter = 0\n",
    "                # Save best model\n",
    "                torch.save(self.model.state_dict(), f'best_{self.model.__class__.__name__.lower()}.pth')\n",
    "                print(\"✓ New best model saved!\")\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                print(f\"Early stopping patience: {patience_counter}/{early_stopping_patience}\")\n",
    "                \n",
    "                if patience_counter >= early_stopping_patience:\n",
    "                    print(\"Early stopping triggered!\")\n",
    "                    break\n",
    "        \n",
    "        print(f\"\\nTraining completed!\")\n",
    "        print(f\"Best validation loss: {best_val_loss:.4f}\")\n",
    "        \n",
    "        # Load best model\n",
    "        self.model.load_state_dict(torch.load(f'best_{self.model.__class__.__name__.lower()}.pth'))\n",
    "        \n",
    "        return self.history\n",
    "\n",
    "def prepare_dataloaders(X, y, model_type, batch_size=32, val_split=0.2, test_split=0.2):\n",
    "    \"\"\"Prepare data loaders for training.\"\"\"\n",
    "    \n",
    "    # Print input shapes and types for debugging\n",
    "    print(f\"Input data types and shapes:\")\n",
    "    print(f\"  X type: {type(X)}, shape: {X.shape}\")\n",
    "    print(f\"  y type: {type(y)}, shape: {y.shape}\")\n",
    "    \n",
    "    # Check if y is one-hot encoded\n",
    "    is_one_hot = len(y.shape) > 1 and y.shape[1] > 1\n",
    "    print(f\"  Labels are {'one-hot encoded' if is_one_hot else 'class indices'}\")\n",
    "    \n",
    "    # If one-hot encoded, convert to class indices for stratification\n",
    "    if is_one_hot:\n",
    "        y_indices = np.argmax(y, axis=1)\n",
    "        print(f\"  Converting to class indices for stratification, shape: {y_indices.shape}\")\n",
    "    else:\n",
    "        y_indices = y\n",
    "    \n",
    "    # Determine if we need sequences\n",
    "    sequence_models = ['lstm', 'cnn_lstm', 'transformer']\n",
    "    sequence_length = 10 if model_type in sequence_models else None\n",
    "    \n",
    "    # Split data\n",
    "    X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "        X, y, test_size=test_split, random_state=42, stratify=y_indices\n",
    "    )\n",
    "    \n",
    "    # For stratification of the validation split\n",
    "    if is_one_hot:\n",
    "        y_temp_indices = np.argmax(y_temp, axis=1)\n",
    "    else:\n",
    "        y_temp_indices = y_temp\n",
    "        \n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_temp, y_temp, test_size=val_split/(1-test_split), \n",
    "        random_state=42, stratify=y_temp_indices\n",
    "    )\n",
    "    \n",
    "    print(f\"Data splits:\")\n",
    "    print(f\"  Train: {len(X_train)} samples\")\n",
    "    print(f\"  Validation: {len(X_val)} samples\")\n",
    "    print(f\"  Test: {len(X_test)} samples\")\n",
    "    if sequence_length:\n",
    "        print(f\"  Sequence length: {sequence_length}\")\n",
    "    \n",
    "    # Create transforms\n",
    "    train_transform, val_transform = create_data_transforms()\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = KeypressDataset(X_train, y_train, train_transform, sequence_length)\n",
    "    val_dataset = KeypressDataset(X_val, y_val, val_transform, sequence_length)\n",
    "    test_dataset = KeypressDataset(X_test, y_test, val_transform, sequence_length)\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "    \n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "def plot_training_history(history, model_name):\n",
    "    \"\"\"Plot training history.\"\"\"\n",
    "    \n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Loss\n",
    "    ax1.plot(history['train_loss'], label='Training Loss')\n",
    "    ax1.plot(history['val_loss'], label='Validation Loss')\n",
    "    ax1.set_title(f'{model_name} - Loss')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True)\n",
    "    \n",
    "    # Accuracy\n",
    "    ax2.plot(history['train_acc'], label='Training Accuracy')\n",
    "    ax2.plot(history['val_acc'], label='Validation Accuracy')\n",
    "    ax2.set_title(f'{model_name} - Accuracy')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Accuracy (%)')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True)\n",
    "    \n",
    "    # Learning rate\n",
    "    ax3.plot(history['learning_rate'])\n",
    "    ax3.set_title(f'{model_name} - Learning Rate')\n",
    "    ax3.set_xlabel('Epoch')\n",
    "    ax3.set_ylabel('Learning Rate')\n",
    "    ax3.set_yscale('log')\n",
    "    ax3.grid(True)\n",
    "    \n",
    "    # Training progress\n",
    "    ax4.plot(history['val_loss'], label='Validation Loss')\n",
    "    ax4.plot(history['val_acc'], label='Validation Accuracy')\n",
    "    ax4.set_title(f'{model_name} - Validation Metrics')\n",
    "    ax4.set_xlabel('Epoch')\n",
    "    ax4.legend()\n",
    "    ax4.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Training configuration\n",
    "MODELS_TO_TRAIN = ['cnn', 'resnet', 'lstm', 'cnn_lstm', 'transformer']\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 50\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "print(\"Training pipeline ready!\")\n",
    "print(f\"Models to train: {MODELS_TO_TRAIN}\")\n",
    "print(f\"Batch size: {BATCH_SIZE}\")\n",
    "print(f\"Epochs: {EPOCHS}\")\n",
    "print(f\"Learning rate: {LEARNING_RATE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c0dc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Multiple Models and Compare Results\n",
    "def train_all_models(X, y, models_to_train=None):\n",
    "    \"\"\"Train all models and compare results.\"\"\"\n",
    "    \n",
    "    if models_to_train is None:\n",
    "        models_to_train = MODELS_TO_TRAIN\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for model_type in models_to_train:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Training {model_type.upper()} Model\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        try:\n",
    "            # Prepare data loaders\n",
    "            train_loader, val_loader, test_loader = prepare_dataloaders(\n",
    "                X, y, model_type, batch_size=BATCH_SIZE\n",
    "            )\n",
    "            \n",
    "            # Create model\n",
    "            model = create_model(model_type)\n",
    "            \n",
    "            # Create trainer\n",
    "            trainer = ModelTrainer(model, device=device, learning_rate=LEARNING_RATE)\n",
    "            \n",
    "            # Train model\n",
    "            history = trainer.train(train_loader, val_loader, epochs=EPOCHS)\n",
    "            \n",
    "            # Plot training history\n",
    "            plot_training_history(history, model_type.upper())\n",
    "            \n",
    "            # Evaluate on test set\n",
    "            test_loss, test_acc = trainer.validate_epoch(test_loader)\n",
    "            \n",
    "            # Store results\n",
    "            results[model_type] = {\n",
    "                'model': trainer.model,\n",
    "                'history': history,\n",
    "                'test_loss': test_loss,\n",
    "                'test_acc': test_acc,\n",
    "                'train_loader': train_loader,\n",
    "                'val_loader': val_loader,\n",
    "                'test_loader': test_loader\n",
    "            }\n",
    "            \n",
    "            print(f\"\\n{model_type.upper()} Results:\")\n",
    "            print(f\"  Test Loss: {test_loss:.4f}\")\n",
    "            print(f\"  Test Accuracy: {test_acc:.2f}%\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error training {model_type}: {e}\")\n",
    "            results[model_type] = {'error': str(e)}\n",
    "        \n",
    "        print(f\"\\n{model_type.upper()} training completed!\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "def compare_models(results):\n",
    "    \"\"\"Compare results from multiple models.\"\"\"\n",
    "    \n",
    "    # Filter out failed models\n",
    "    successful_results = {k: v for k, v in results.items() if 'error' not in v}\n",
    "    \n",
    "    if not successful_results:\n",
    "        print(\"No successful model training results to compare.\")\n",
    "        return\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"MODEL COMPARISON RESULTS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Create comparison table\n",
    "    comparison_data = []\n",
    "    for model_type, result in successful_results.items():\n",
    "        final_val_acc = result['history']['val_acc'][-1]\n",
    "        best_val_acc = max(result['history']['val_acc'])\n",
    "        final_val_loss = result['history']['val_loss'][-1]\n",
    "        best_val_loss = min(result['history']['val_loss'])\n",
    "        \n",
    "        comparison_data.append({\n",
    "            'Model': model_type.upper(),\n",
    "            'Test Accuracy': f\"{result['test_acc']:.2f}%\",\n",
    "            'Best Val Accuracy': f\"{best_val_acc:.2f}%\",\n",
    "            'Final Val Loss': f\"{final_val_loss:.4f}\",\n",
    "            'Best Val Loss': f\"{best_val_loss:.4f}\",\n",
    "            'Training Epochs': len(result['history']['train_loss'])\n",
    "        })\n",
    "    \n",
    "    # Display comparison table\n",
    "    df = pd.DataFrame(comparison_data)\n",
    "    print(df.to_string(index=False))\n",
    "    \n",
    "    # Plot comparison\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # Test accuracy comparison\n",
    "    models = list(successful_results.keys())\n",
    "    test_accs = [successful_results[m]['test_acc'] for m in models]\n",
    "    \n",
    "    ax1.bar(models, test_accs, color=['skyblue', 'lightgreen', 'lightcoral', 'gold', 'lightpink'][:len(models)])\n",
    "    ax1.set_title('Test Accuracy Comparison')\n",
    "    ax1.set_ylabel('Accuracy (%)')\n",
    "    ax1.set_ylim(0, 100)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for i, v in enumerate(test_accs):\n",
    "        ax1.text(i, v + 1, f'{v:.2f}%', ha='center', va='bottom')\n",
    "    \n",
    "    # Validation accuracy over time\n",
    "    for model_type in models:\n",
    "        history = successful_results[model_type]['history']\n",
    "        ax2.plot(history['val_acc'], label=model_type.upper())\n",
    "    \n",
    "    ax2.set_title('Validation Accuracy Over Time')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Accuracy (%)')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True)\n",
    "    \n",
    "    # Validation loss over time\n",
    "    for model_type in models:\n",
    "        history = successful_results[model_type]['history']\n",
    "        ax3.plot(history['val_loss'], label=model_type.upper())\n",
    "    \n",
    "    ax3.set_title('Validation Loss Over Time')\n",
    "    ax3.set_xlabel('Epoch')\n",
    "    ax3.set_ylabel('Loss')\n",
    "    ax3.legend()\n",
    "    ax3.grid(True)\n",
    "    \n",
    "    # Training time comparison (epochs to convergence)\n",
    "    epochs_to_convergence = [len(successful_results[m]['history']['train_loss']) for m in models]\n",
    "    \n",
    "    ax4.bar(models, epochs_to_convergence, color=['skyblue', 'lightgreen', 'lightcoral', 'gold', 'lightpink'][:len(models)])\n",
    "    ax4.set_title('Training Time Comparison')\n",
    "    ax4.set_ylabel('Epochs to Convergence')\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for i, v in enumerate(epochs_to_convergence):\n",
    "        ax4.text(i, v + 0.5, f'{v}', ha='center', va='bottom')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Find best model\n",
    "    best_model = max(successful_results.keys(), key=lambda x: successful_results[x]['test_acc'])\n",
    "    print(f\"\\n🏆 Best performing model: {best_model.upper()}\")\n",
    "    print(f\"   Test Accuracy: {successful_results[best_model]['test_acc']:.2f}%\")\n",
    "    \n",
    "    return successful_results\n",
    "\n",
    "# Execute training if data is available\n",
    "if 'X' in locals() and 'y' in locals() and len(X) > 0:\n",
    "    print(\"Starting multi-model training...\")\n",
    "    \n",
    "    # Train all models\n",
    "    training_results = train_all_models(X, y)\n",
    "    \n",
    "    # Compare results\n",
    "    comparison_results = compare_models(training_results)\n",
    "    \n",
    "    print(\"\\n✅ Multi-model training completed!\")\n",
    "    \n",
    "else:\n",
    "    print(\"❌ No data available for training\")\n",
    "    print(\"Please run the data loading cell first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da24ae81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed Model Evaluation and Analysis\n",
    "def evaluate_model_detailed(model, test_loader, model_name):\n",
    "    \"\"\"Detailed evaluation of a single model.\"\"\"\n",
    "    \n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y in test_loader:\n",
    "            # First, let's print the shape of batch_y to understand its format\n",
    "            print(f\"Debug - batch_y shape: {batch_y.shape}, batch_y type: {type(batch_y)}\")\n",
    "            \n",
    "            batch_x = batch_x.to(device)\n",
    "            batch_y = batch_y.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(batch_x)\n",
    "            \n",
    "            # Get predicted class\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            # Also get probabilities for AUC and other metrics\n",
    "            probs = F.softmax(outputs, dim=1).cpu().numpy()  # Using softmax instead of sigmoid\n",
    "            \n",
    "            # Convert to numpy for metrics calculation\n",
    "            preds = predicted.cpu().numpy()\n",
    "            \n",
    "            # Handle labels based on their format\n",
    "            if len(batch_y.shape) > 1 and batch_y.shape[1] > 1:\n",
    "                # One-hot encoded labels\n",
    "                batch_labels = torch.max(batch_y, 1)[1].cpu().numpy()\n",
    "            else:\n",
    "                # Class indices\n",
    "                batch_labels = batch_y.cpu().numpy()\n",
    "            \n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(batch_labels)\n",
    "            \n",
    "            # For binary classification, take probability of class 1\n",
    "            if probs.shape[1] >= 2:\n",
    "                all_probs.extend(probs[:, 1])  # Probability of class 1 (pressed)\n",
    "            else:\n",
    "                all_probs.extend(probs.flatten())\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_labels = np.array(all_labels)\n",
    "    all_probs = np.array(all_probs)\n",
    "    \n",
    "    # Print debug info\n",
    "    print(f\"Debug Info:\")\n",
    "    print(f\"  - all_preds shape: {all_preds.shape}\")\n",
    "    print(f\"  - all_labels shape: {all_labels.shape}\")\n",
    "    print(f\"  - all_probs shape: {all_probs.shape}\")\n",
    "    if len(all_preds) > 0:\n",
    "        print(f\"  - preds distribution: {np.bincount(all_preds)}\")\n",
    "    if len(all_labels) > 0:\n",
    "        print(f\"  - labels distribution: {np.bincount(all_labels.astype(int))}\")\n",
    "    \n",
    "    # Check for length mismatch and fix if needed\n",
    "    min_len = min(len(all_preds), len(all_labels), len(all_probs))\n",
    "    if len(all_preds) != len(all_labels) or len(all_preds) != len(all_probs):\n",
    "        print(f\"⚠️ Length mismatch detected: preds={len(all_preds)}, labels={len(all_labels)}, probs={len(all_probs)}\")\n",
    "        print(f\"   Truncating to minimum length: {min_len}\")\n",
    "        all_preds = all_preds[:min_len]\n",
    "        all_labels = all_labels[:min_len]\n",
    "        all_probs = all_probs[:min_len]\n",
    "    \n",
    "    # Calculate metrics\n",
    "    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\n",
    "    \n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds, zero_division=0)\n",
    "    recall = recall_score(all_labels, all_preds, zero_division=0)\n",
    "    f1 = f1_score(all_labels, all_preds, zero_division=0)\n",
    "    \n",
    "    try:\n",
    "        auc = roc_auc_score(all_labels, all_probs)\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ AUC calculation failed: {e}\")\n",
    "        auc = 0.0\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    \n",
    "    print(f\"\\n{model_name} - Detailed Evaluation:\")\n",
    "    print(f\"  Samples evaluated: {len(all_labels)}\")\n",
    "    print(f\"  Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"  Precision: {precision:.4f}\")\n",
    "    print(f\"  Recall:    {recall:.4f}\")\n",
    "    print(f\"  F1-Score:  {f1:.4f}\")\n",
    "    print(f\"  AUC:       {auc:.4f}\")\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=['No Press', 'Key Press'], \n",
    "                yticklabels=['No Press', 'Key Press'])\n",
    "    plt.title(f'{model_name} - Confusion Matrix')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.show()\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'auc': auc,\n",
    "        'predictions': all_preds,\n",
    "        'labels': all_labels,\n",
    "        'probabilities': all_probs\n",
    "    }\n",
    "\n",
    "def predict_single_image(model, image_array, model_type='cnn'):\n",
    "    \"\"\"\n",
    "    Predicts key press for a single image.\n",
    "    \n",
    "    Args:\n",
    "        model: The trained PyTorch model\n",
    "        image_array: Numpy array of shape (H, W, C) or (C, H, W)\n",
    "        model_type: Type of model ('cnn', 'resnet', 'lstm', 'cnn_lstm', 'transformer')\n",
    "                   \n",
    "    Returns:\n",
    "        prediction: Class prediction (0 or 1)\n",
    "        probability: Probability of the positive class (key press)\n",
    "        class_probs: Probabilities for all classes\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Ensure image is a numpy array\n",
    "    if not isinstance(image_array, np.ndarray):\n",
    "        raise ValueError(\"Image must be a numpy array\")\n",
    "    \n",
    "    # Handle different image formats\n",
    "    # Check if image is in PyTorch format (C, H, W) or standard format (H, W, C)\n",
    "    if image_array.shape[0] == 3 and len(image_array.shape) == 3:\n",
    "        # Already in PyTorch format (C, H, W)\n",
    "        image_tensor = torch.FloatTensor(image_array)\n",
    "    elif len(image_array.shape) == 3 and image_array.shape[2] == 3:\n",
    "        # Convert from (H, W, C) to (C, H, W)\n",
    "        image_tensor = torch.FloatTensor(np.transpose(image_array, (2, 0, 1)))\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported image shape: {image_array.shape}, expected (3, H, W) or (H, W, 3)\")\n",
    "    \n",
    "    # Handle sequence models\n",
    "    if model_type in ['lstm', 'cnn_lstm', 'transformer']:\n",
    "        # For sequence models, add sequence dimension\n",
    "        image_tensor = image_tensor.unsqueeze(0).unsqueeze(0)  # (1, 1, C, H, W)\n",
    "    else:\n",
    "        # For CNN models, add batch dimension\n",
    "        image_tensor = image_tensor.unsqueeze(0)  # (1, C, H, W)\n",
    "    \n",
    "    # Move to device and ensure model is in eval mode\n",
    "    image_tensor = image_tensor.to(device)\n",
    "    \n",
    "    # Perform inference\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image_tensor)\n",
    "        \n",
    "        # Get class probabilities\n",
    "        if outputs.shape[1] > 1:\n",
    "            # Multi-class output\n",
    "            probs = F.softmax(outputs, dim=1).cpu().numpy()[0]\n",
    "            prediction = np.argmax(probs)\n",
    "            probability = probs[1] if len(probs) > 1 else probs[0]\n",
    "        else:\n",
    "            # Binary output\n",
    "            probs = torch.sigmoid(outputs).cpu().numpy()[0]\n",
    "            prediction = (probs > 0.5).astype(int)[0]\n",
    "            probability = probs[0]\n",
    "            probs = np.array([1 - probability, probability])  # Convert to [not_pressed, pressed]\n",
    "    \n",
    "    return prediction, probability, probs\n",
    "\n",
    "def predict_image_sequence(model, image_sequence, model_type='cnn_lstm'):\n",
    "    \"\"\"Predict keypress for a sequence of images.\"\"\"\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    # Ensure image sequence is the right format\n",
    "    if isinstance(image_sequence, list):\n",
    "        image_sequence = np.array(image_sequence)\n",
    "    \n",
    "    # Check sequence format\n",
    "    if len(image_sequence.shape) != 4:  # (seq_len, C, H, W)\n",
    "        raise ValueError(f\"Expected sequence shape (seq_len, C, H, W), got {image_sequence.shape}\")\n",
    "    \n",
    "    # Convert to tensor\n",
    "    seq_tensor = torch.FloatTensor(image_sequence).unsqueeze(0)  # Add batch dim\n",
    "    seq_tensor = seq_tensor.to(device)\n",
    "    \n",
    "    # Perform inference\n",
    "    with torch.no_grad():\n",
    "        outputs = model(seq_tensor)\n",
    "        \n",
    "        # Get class probabilities\n",
    "        if outputs.shape[1] > 1:\n",
    "            # Multi-class output\n",
    "            probs = F.softmax(outputs, dim=1).cpu().numpy()[0]\n",
    "            prediction = np.argmax(probs)\n",
    "            probability = probs[1] if len(probs) > 1 else probs[0]\n",
    "        else:\n",
    "            # Binary output\n",
    "            probs = torch.sigmoid(outputs).cpu().numpy()[0]\n",
    "            prediction = (probs > 0.5).astype(int)[0]\n",
    "            probability = probs[0]\n",
    "            probs = np.array([1 - probability, probability])  # Convert to [not_pressed, pressed]\n",
    "    \n",
    "    return prediction, probability, probs\n",
    "\n",
    "def analyze_predictions(results, model_names):\n",
    "    \"\"\"Analyze predictions across all models.\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"DETAILED PREDICTION ANALYSIS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Create comprehensive metrics table\n",
    "    metrics_data = []\n",
    "    for model_name in model_names:\n",
    "        if model_name in results and 'error' not in results[model_name]:\n",
    "            eval_results = evaluate_model_detailed(\n",
    "                results[model_name]['model'], \n",
    "                results[model_name]['test_loader'], \n",
    "                model_name.upper()\n",
    "            )\n",
    "            \n",
    "            metrics_data.append({\n",
    "                'Model': model_name.upper(),\n",
    "                'Accuracy': f\"{eval_results['accuracy']:.4f}\",\n",
    "                'Precision': f\"{eval_results['precision']:.4f}\",\n",
    "                'Recall': f\"{eval_results['recall']:.4f}\",\n",
    "                'F1-Score': f\"{eval_results['f1']:.4f}\",\n",
    "                'AUC': f\"{eval_results['auc']:.4f}\"\n",
    "            })\n",
    "    \n",
    "    # Display metrics table\n",
    "    if metrics_data:\n",
    "        df = pd.DataFrame(metrics_data)\n",
    "        print(\"\\n📊 Comprehensive Metrics Comparison:\")\n",
    "        print(df.to_string(index=False))\n",
    "        \n",
    "        # Plot metrics comparison\n",
    "        fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'AUC']\n",
    "        \n",
    "        for i, metric in enumerate(metrics):\n",
    "            values = [float(row[metric]) for row in metrics_data]\n",
    "            models = [row['Model'] for row in metrics_data]\n",
    "            \n",
    "            bars = axes[i].bar(models, values, color=['skyblue', 'lightgreen', 'lightcoral', 'gold', 'lightpink'][:len(models)])\n",
    "            axes[i].set_title(f'{metric} Comparison')\n",
    "            axes[i].set_ylabel(metric)\n",
    "            axes[i].set_ylim(0, 1)\n",
    "            \n",
    "            # Add value labels\n",
    "            for bar, value in zip(bars, values):\n",
    "                axes[i].text(bar.get_x() + bar.get_width()/2., bar.get_height() + 0.01, \n",
    "                           f'{value:.3f}', ha='center', va='bottom')\n",
    "        \n",
    "        # Remove empty subplot\n",
    "        axes[5].remove()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Example of using predict_single_image\n",
    "def demonstrate_single_image_prediction():\n",
    "    \"\"\"Demonstrate using predict_single_image with a sample image.\"\"\"\n",
    "    if 'training_results' in locals() and 'X_processed' in locals():\n",
    "        # Get a sample image from the test data\n",
    "        test_loader = next(iter(training_results.values()))['test_loader']\n",
    "        batch_x, _ = next(iter(test_loader))\n",
    "        sample_image = batch_x[0].numpy()  # First image in batch\n",
    "        \n",
    "        # Test with each model\n",
    "        for model_name, result in training_results.items():\n",
    "            if 'error' not in result:\n",
    "                model = result['model']\n",
    "                prediction, probability, class_probs = predict_single_image(\n",
    "                    model, sample_image, model_type=model_name\n",
    "                )\n",
    "                \n",
    "                print(f\"{model_name.upper()} prediction:\")\n",
    "                print(f\"  Class: {'Pressed' if prediction == 1 else 'Not Pressed'}\")\n",
    "                print(f\"  Probability: {probability:.4f}\")\n",
    "                print(f\"  Class probabilities: {class_probs}\")\n",
    "                print()\n",
    "\n",
    "# Perform detailed evaluation if training results exist\n",
    "if 'training_results' in locals():\n",
    "    analyze_predictions(training_results, list(training_results.keys()))\n",
    "else:\n",
    "    print(\"❌ No training results available for detailed evaluation\")\n",
    "    print(\"Please run the training cell first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de964b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Inference and Prediction Functions\n",
    "def detect_model_type(model):\n",
    "    \"\"\"Automatically detect the model type based on architecture.\"\"\"\n",
    "    model_name = model.__class__.__name__.lower()\n",
    "    \n",
    "    if 'lstm' in model_name and 'cnn' in model_name:\n",
    "        return 'cnn_lstm'\n",
    "    elif 'lstm' in model_name:\n",
    "        return 'lstm'\n",
    "    elif 'cnn' in model_name or 'resnet' in model_name or 'transformer' in model_name:\n",
    "        return 'cnn'\n",
    "    else:\n",
    "        # Default fallback\n",
    "        return 'cnn'\n",
    "\n",
    "def predict_single_image(model, image_array, model_type=None):\n",
    "    \"\"\"Predict keypress for a single image.\"\"\"\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    # Auto-detect model type if not provided\n",
    "    if model_type is None:\n",
    "        model_type = detect_model_type(model)\n",
    "    \n",
    "    # Prepare image - ensure it matches training data format\n",
    "    if len(image_array.shape) == 3:\n",
    "        image_array = np.expand_dims(image_array, axis=0)\n",
    "    \n",
    "    # Convert to tensor and move to device\n",
    "    image_tensor = torch.FloatTensor(image_array).to(device)\n",
    "    \n",
    "    # Handle different model types\n",
    "    if model_type in ['lstm', 'cnn_lstm']:\n",
    "        # For LSTM models, we need sequence dimension\n",
    "        if len(image_tensor.shape) == 4:\n",
    "            image_tensor = image_tensor.unsqueeze(1)  # Add sequence dimension\n",
    "    \n",
    "    try:\n",
    "        with torch.no_grad():\n",
    "            outputs = model(image_tensor)\n",
    "            \n",
    "            # Use the same approach as evaluate_model_detailed\n",
    "            if len(outputs.shape) > 1 and outputs.shape[1] > 1:  # Multi-class output\n",
    "                # Get predicted class using argmax\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                # Get probabilities using softmax\n",
    "                probs = torch.softmax(outputs, dim=1).cpu().numpy()\n",
    "                prediction = predicted.cpu().item()\n",
    "                probability = probs[0][1] if probs.shape[1] > 1 else probs[0][0]\n",
    "            else:  # Single output (binary classification with sigmoid)\n",
    "                # Use sigmoid for single output\n",
    "                probability = torch.sigmoid(outputs).cpu().numpy()[0][0]\n",
    "                prediction = int(probability > 0.5)\n",
    "        \n",
    "        return prediction, probability\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error in predict_single_image: {e}\")\n",
    "        print(f\"   Model type: {model_type}\")\n",
    "        print(f\"   Input shape: {image_tensor.shape}\")\n",
    "        return 0, 0.0\n",
    "\n",
    "def predict_single_image_robust(model, image_array, model_type=None, transforms=None):\n",
    "    \"\"\"Enhanced single image prediction with proper preprocessing.\"\"\"\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    # Auto-detect model type if not provided\n",
    "    if model_type is None:\n",
    "        model_type = detect_model_type(model)\n",
    "    \n",
    "    # Apply transforms if provided (should match training transforms)\n",
    "    if transforms is not None:\n",
    "        # Convert numpy array to PIL Image if needed\n",
    "        if isinstance(image_array, np.ndarray):\n",
    "            if image_array.dtype != np.uint8:\n",
    "                image_array = (image_array * 255).astype(np.uint8)\n",
    "            from PIL import Image\n",
    "            if len(image_array.shape) == 3:\n",
    "                image_pil = Image.fromarray(image_array)\n",
    "            else:\n",
    "                image_pil = Image.fromarray(image_array[0])\n",
    "            \n",
    "            # Apply transforms\n",
    "            image_tensor = transforms(image_pil).unsqueeze(0).to(device)\n",
    "        else:\n",
    "            image_tensor = transforms(image_array).unsqueeze(0).to(device)\n",
    "    else:\n",
    "        # Manual preprocessing\n",
    "        if len(image_array.shape) == 3:\n",
    "            image_array = np.expand_dims(image_array, axis=0)\n",
    "        \n",
    "        # Normalize to [0, 1] if not already\n",
    "        if image_array.max() > 1.0:\n",
    "            image_array = image_array.astype(np.float32) / 255.0\n",
    "        \n",
    "        # Convert to tensor\n",
    "        image_tensor = torch.FloatTensor(image_array).to(device)\n",
    "    \n",
    "    # Handle different model types\n",
    "    if model_type in ['lstm', 'cnn_lstm']:\n",
    "        if len(image_tensor.shape) == 4:\n",
    "            image_tensor = image_tensor.unsqueeze(1)\n",
    "    \n",
    "    try:\n",
    "        with torch.no_grad():\n",
    "            outputs = model(image_tensor)\n",
    "            \n",
    "            # Debug information\n",
    "            print(f\"Model type: {model_type}\")\n",
    "            print(f\"Input shape: {image_tensor.shape}\")\n",
    "            print(f\"Model output shape: {outputs.shape}\")\n",
    "            \n",
    "            # Handle output based on shape\n",
    "            if len(outputs.shape) > 1 and outputs.shape[1] > 1:  # Multi-class\n",
    "                # Use softmax and argmax like in evaluate_model_detailed\n",
    "                probs = torch.softmax(outputs, dim=1)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                \n",
    "                prediction = predicted.cpu().item()\n",
    "                probability = probs[0][1].cpu().item() if probs.shape[1] > 1 else probs[0][0].cpu().item()\n",
    "                \n",
    "                print(f\"Multi-class prediction: {prediction}, probability: {probability}\")\n",
    "            else:  # Single output\n",
    "                # Use sigmoid\n",
    "                probability = torch.sigmoid(outputs).cpu().item()\n",
    "                prediction = int(probability > 0.5)\n",
    "                \n",
    "                print(f\"Binary prediction: {prediction}, probability: {probability}\")\n",
    "        \n",
    "        return prediction, probability\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error in predict_single_image_robust: {e}\")\n",
    "        print(f\"   Model type: {model_type}\")\n",
    "        print(f\"   Input shape: {image_tensor.shape}\")\n",
    "        return 0, 0.0\n",
    "\n",
    "def predict_image_sequence(model, image_sequence, model_type=None):\n",
    "    \"\"\"Predict keypress for a sequence of images (for LSTM models).\"\"\"\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    # Auto-detect model type if not provided\n",
    "    if model_type is None:\n",
    "        model_type = detect_model_type(model)\n",
    "    \n",
    "    # Prepare sequence\n",
    "    if len(image_sequence.shape) == 4:\n",
    "        image_sequence = np.expand_dims(image_sequence, axis=0)\n",
    "    \n",
    "    # Convert to tensor\n",
    "    sequence_tensor = torch.FloatTensor(image_sequence).to(device)\n",
    "    \n",
    "    try:\n",
    "        with torch.no_grad():\n",
    "            outputs = model(sequence_tensor)\n",
    "            \n",
    "            # Use consistent output handling\n",
    "            if len(outputs.shape) > 1 and outputs.shape[1] > 1:  # Multi-class\n",
    "                probs = torch.softmax(outputs, dim=1)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                prediction = predicted.cpu().item()\n",
    "                probability = probs[0][1].cpu().item()\n",
    "            else:  # Single output\n",
    "                probability = torch.sigmoid(outputs).cpu().item()\n",
    "                prediction = int(probability > 0.5)\n",
    "        \n",
    "        return prediction, probability\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error in predict_image_sequence: {e}\")\n",
    "        return 0, 0.0\n",
    "\n",
    "def batch_predict(model, images, model_type=None, batch_size=32):\n",
    "    \"\"\"Predict keypress for multiple images in batches.\"\"\"\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    # Auto-detect model type if not provided\n",
    "    if model_type is None:\n",
    "        model_type = detect_model_type(model)\n",
    "    \n",
    "    predictions = []\n",
    "    probabilities = []\n",
    "    \n",
    "    # Process in batches\n",
    "    for i in range(0, len(images), batch_size):\n",
    "        batch_images = images[i:i+batch_size]\n",
    "        \n",
    "        # Convert to tensor\n",
    "        batch_tensor = torch.FloatTensor(batch_images).to(device)\n",
    "        \n",
    "        # Handle different model types\n",
    "        if model_type in ['lstm', 'cnn_lstm']:\n",
    "            if len(batch_tensor.shape) == 4:\n",
    "                batch_tensor = batch_tensor.unsqueeze(1)\n",
    "        \n",
    "        try:\n",
    "            with torch.no_grad():\n",
    "                outputs = model(batch_tensor)\n",
    "                \n",
    "                # Use consistent output handling\n",
    "                if len(outputs.shape) > 1 and outputs.shape[1] > 1:  # Multi-class\n",
    "                    probs = torch.softmax(outputs, dim=1).cpu().numpy()\n",
    "                    batch_preds = np.argmax(probs, axis=1)\n",
    "                    batch_probs = probs[:, 1] if probs.shape[1] > 1 else probs[:, 0]\n",
    "                else:  # Single output\n",
    "                    batch_probs = torch.sigmoid(outputs).cpu().numpy().flatten()\n",
    "                    batch_preds = (batch_probs > 0.5).astype(int)\n",
    "            \n",
    "            predictions.extend(batch_preds)\n",
    "            probabilities.extend(batch_probs)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error in batch {i//batch_size + 1}: {e}\")\n",
    "            # Fill with default values for this batch\n",
    "            batch_size_actual = len(batch_images)\n",
    "            predictions.extend([0] * batch_size_actual)\n",
    "            probabilities.extend([0.0] * batch_size_actual)\n",
    "    \n",
    "    return predictions, probabilities\n",
    "\n",
    "def test_single_image_prediction(model, test_loader, model_name, num_tests=5):\n",
    "    \"\"\"Test single image prediction against batch evaluation.\"\"\"\n",
    "    \n",
    "    print(f\"\\n🧪 Testing single image prediction for {model_name}\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    # Auto-detect model type\n",
    "    model_type = detect_model_type(model)\n",
    "    print(f\"Detected model type: {model_type}\")\n",
    "    \n",
    "    # Get some test samples\n",
    "    batch_x, batch_y = next(iter(test_loader))\n",
    "    \n",
    "    for i in range(min(num_tests, len(batch_x))):\n",
    "        try:\n",
    "            # Get single image\n",
    "            single_image = batch_x[i].cpu().numpy()\n",
    "            true_label = batch_y[i].cpu().item() if len(batch_y[i].shape) == 0 else batch_y[i].cpu().numpy()\n",
    "            \n",
    "            # Predict using single image function\n",
    "            pred_single, prob_single = predict_single_image(model, single_image, model_type)\n",
    "            \n",
    "            # Predict using batch (for comparison)\n",
    "            with torch.no_grad():\n",
    "                batch_tensor = batch_x[i:i+1].to(device)\n",
    "                \n",
    "                # Handle LSTM models properly\n",
    "                if model_type in ['lstm', 'cnn_lstm'] and len(batch_tensor.shape) == 4:\n",
    "                    batch_tensor = batch_tensor.unsqueeze(1)\n",
    "                \n",
    "                outputs = model(batch_tensor)\n",
    "                \n",
    "                if len(outputs.shape) > 1 and outputs.shape[1] > 1:\n",
    "                    probs = torch.softmax(outputs, dim=1)\n",
    "                    _, predicted = torch.max(outputs, 1)\n",
    "                    pred_batch = predicted.cpu().item()\n",
    "                    prob_batch = probs[0][1].cpu().item()\n",
    "                else:\n",
    "                    prob_batch = torch.sigmoid(outputs).cpu().item()\n",
    "                    pred_batch = int(prob_batch > 0.5)\n",
    "            \n",
    "            # Compare results\n",
    "            match = \"✅\" if pred_single == pred_batch else \"❌\"\n",
    "            print(f\"Sample {i+1}: True={true_label} | Single={pred_single}({prob_single:.3f}) | Batch={pred_batch}({prob_batch:.3f}) {match}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error testing sample {i+1}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    return True\n",
    "\n",
    "def visualize_predictions(model, test_loader, model_name, num_samples=16):\n",
    "    \"\"\"Visualize model predictions on test samples.\"\"\"\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    # Auto-detect model type\n",
    "    model_type = detect_model_type(model)\n",
    "    \n",
    "    # Get a batch of test data\n",
    "    batch_x, batch_y = next(iter(test_loader))\n",
    "    batch_x = batch_x[:num_samples]\n",
    "    batch_y = batch_y[:num_samples]\n",
    "    \n",
    "    # Make predictions\n",
    "    try:\n",
    "        with torch.no_grad():\n",
    "            batch_x_gpu = batch_x.to(device)\n",
    "            \n",
    "            # Handle LSTM models properly\n",
    "            if model_type in ['lstm', 'cnn_lstm'] and len(batch_x_gpu.shape) == 4:\n",
    "                batch_x_gpu = batch_x_gpu.unsqueeze(1)\n",
    "            \n",
    "            outputs = model(batch_x_gpu)\n",
    "            \n",
    "            # Handle different output formats\n",
    "            if len(outputs.shape) > 1 and outputs.shape[1] > 1:  # Multi-class\n",
    "                probs = torch.softmax(outputs, dim=1).cpu().numpy()\n",
    "                preds = np.argmax(probs, axis=1)\n",
    "                probs_display = probs[:, 1] if probs.shape[1] > 1 else probs[:, 0]\n",
    "            else:  # Single output\n",
    "                probs_display = torch.sigmoid(outputs).cpu().numpy().flatten()\n",
    "                preds = (probs_display > 0.5).astype(int)\n",
    "        \n",
    "        # Create visualization\n",
    "        fig, axes = plt.subplots(4, 4, figsize=(16, 16))\n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        for i in range(num_samples):\n",
    "            # Get image\n",
    "            if len(batch_x[i].shape) == 4:  # For LSTM models\n",
    "                img = batch_x[i][0].permute(1, 2, 0).numpy()\n",
    "            else:  # For CNN models\n",
    "                img = batch_x[i].permute(1, 2, 0).numpy()\n",
    "            \n",
    "            # Denormalize if needed\n",
    "            if img.min() < 0:\n",
    "                img = (img + 1) / 2\n",
    "            \n",
    "            # Plot\n",
    "            axes[i].imshow(img)\n",
    "            axes[i].axis('off')\n",
    "            \n",
    "            # Add prediction info\n",
    "            true_label = \"Press\" if batch_y[i].item() == 1 else \"No Press\"\n",
    "            pred_label = \"Press\" if preds[i] == 1 else \"No Press\"\n",
    "            prob = probs_display[i]\n",
    "            \n",
    "            color = 'green' if preds[i] == batch_y[i].item() else 'red'\n",
    "            axes[i].set_title(f'True: {true_label}\\nPred: {pred_label}\\nProb: {prob:.3f}', \n",
    "                             color=color, fontsize=10)\n",
    "        \n",
    "        plt.suptitle(f'{model_name} - Sample Predictions (Type: {model_type})', fontsize=16)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error in visualization: {e}\")\n",
    "        print(f\"   Model type: {model_type}\")\n",
    "        print(f\"   Input shape: {batch_x_gpu.shape}\")\n",
    "\n",
    "def test_inference_speed(model, test_loader, model_name):\n",
    "    \"\"\"Test inference speed of the model.\"\"\"\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    # Auto-detect model type\n",
    "    model_type = detect_model_type(model)\n",
    "    \n",
    "    try:\n",
    "        # Warm up\n",
    "        with torch.no_grad():\n",
    "            batch_x, _ = next(iter(test_loader))\n",
    "            batch_x = batch_x.to(device)\n",
    "            \n",
    "            # Handle LSTM models\n",
    "            if model_type in ['lstm', 'cnn_lstm'] and len(batch_x.shape) == 4:\n",
    "                batch_x = batch_x.unsqueeze(1)\n",
    "            \n",
    "            _ = model(batch_x)\n",
    "        \n",
    "        # Time inference\n",
    "        import time\n",
    "        \n",
    "        start_time = time.time()\n",
    "        total_samples = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch_x, _ in test_loader:\n",
    "                batch_x = batch_x.to(device)\n",
    "                \n",
    "                # Handle LSTM models\n",
    "                if model_type in ['lstm', 'cnn_lstm'] and len(batch_x.shape) == 4:\n",
    "                    batch_x = batch_x.unsqueeze(1)\n",
    "                \n",
    "                _ = model(batch_x)\n",
    "                total_samples += batch_x.size(0)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        \n",
    "        total_time = end_time - start_time\n",
    "        fps = total_samples / total_time\n",
    "        \n",
    "        print(f\"\\n{model_name} Inference Speed:\")\n",
    "        print(f\"  Model type: {model_type}\")\n",
    "        print(f\"  Total samples: {total_samples}\")\n",
    "        print(f\"  Total time: {total_time:.2f} seconds\")\n",
    "        print(f\"  FPS: {fps:.2f} frames/second\")\n",
    "        print(f\"  Average time per frame: {1/fps*1000:.2f} ms\")\n",
    "        \n",
    "        return fps\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error in speed test: {e}\")\n",
    "        return 0\n",
    "\n",
    "# Demo predictions if training results exist\n",
    "if 'training_results' in locals():\n",
    "    print(\"🔮 Running inference demonstrations...\")\n",
    "    \n",
    "    # Test inference for each successful model\n",
    "    for model_name, result in training_results.items():\n",
    "        if 'error' not in result:\n",
    "            print(f\"\\n{'='*40}\")\n",
    "            print(f\"Testing {model_name.upper()} Model\")\n",
    "            print(f\"{'='*40}\")\n",
    "            \n",
    "            try:\n",
    "                # Test single image prediction consistency\n",
    "                test_single_image_prediction(result['model'], result['test_loader'], model_name.upper())\n",
    "                \n",
    "                # Visualize predictions\n",
    "                visualize_predictions(result['model'], result['test_loader'], model_name.upper())\n",
    "                \n",
    "                # Test inference speed\n",
    "                fps = test_inference_speed(result['model'], result['test_loader'], model_name.upper())\n",
    "                \n",
    "                print(f\"\\n✅ {model_name.upper()} inference testing completed!\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"❌ Error testing {model_name.upper()}: {e}\")\n",
    "                continue\n",
    "    \n",
    "else:\n",
    "    print(\"❌ No training results available for inference testing\")\n",
    "    print(\"Please run the training cell first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658b4c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter Optimization and Tuning\n",
    "def optimize_hyperparameters(X, y, model_type='cnn', max_trials=10):\n",
    "    \"\"\"Optimize hyperparameters using random search.\"\"\"\n",
    "    \n",
    "    print(f\"🔍 Starting hyperparameter optimization for {model_type.upper()}\")\n",
    "    \n",
    "    # Define hyperparameter search space\n",
    "    param_space = {\n",
    "        'learning_rate': [0.001, 0.0001, 0.00001],\n",
    "        'batch_size': [16, 32, 64],\n",
    "        'dropout_rate': [0.2, 0.3, 0.5],\n",
    "        'hidden_size': [64, 128, 256] if model_type in ['lstm', 'cnn_lstm'] else [None],\n",
    "        'num_layers': [1, 2, 3] if model_type in ['lstm', 'cnn_lstm'] else [None]\n",
    "    }\n",
    "    \n",
    "    best_score = 0\n",
    "    best_params = None\n",
    "    trial_results = []\n",
    "    \n",
    "    for trial in range(max_trials):\n",
    "        print(f\"\\n--- Trial {trial + 1}/{max_trials} ---\")\n",
    "        \n",
    "        # Sample random hyperparameters\n",
    "        params = {}\n",
    "        for param_name, values in param_space.items():\n",
    "            if values[0] is not None:  # Skip None values\n",
    "                params[param_name] = random.choice(values)\n",
    "        \n",
    "        print(f\"Testing parameters: {params}\")\n",
    "        \n",
    "        try:\n",
    "            # Prepare data with current batch size\n",
    "            train_loader, val_loader, test_loader = prepare_dataloaders(\n",
    "                X, y, model_type, batch_size=params.get('batch_size', 32)\n",
    "            )\n",
    "            \n",
    "            # Create model with current parameters\n",
    "            if model_type == 'cnn':\n",
    "                model = CNNModel(dropout_rate=params.get('dropout_rate', 0.3))\n",
    "            elif model_type == 'lstm':\n",
    "                model = LSTMModel(\n",
    "                    hidden_size=params.get('hidden_size', 128),\n",
    "                    num_layers=params.get('num_layers', 2),\n",
    "                    dropout_rate=params.get('dropout_rate', 0.3)\n",
    "                )\n",
    "            elif model_type == 'cnn_lstm':\n",
    "                model = CNNLSTMModel(\n",
    "                    lstm_hidden_size=params.get('hidden_size', 128),\n",
    "                    lstm_num_layers=params.get('num_layers', 2),\n",
    "                    dropout_rate=params.get('dropout_rate', 0.3)\n",
    "                )\n",
    "            else:\n",
    "                model = create_model(model_type)\n",
    "            \n",
    "            # Train with early stopping\n",
    "            trainer = ModelTrainer(\n",
    "                model, \n",
    "                device=device, \n",
    "                learning_rate=params.get('learning_rate', 0.001)\n",
    "            )\n",
    "            \n",
    "            # Shorter training for optimization\n",
    "            history = trainer.train(train_loader, val_loader, epochs=20)\n",
    "            \n",
    "            # Evaluate\n",
    "            val_loss, val_acc = trainer.validate_epoch(val_loader)\n",
    "            \n",
    "            # Store results\n",
    "            trial_results.append({\n",
    "                'trial': trial + 1,\n",
    "                'params': params.copy(),\n",
    "                'val_acc': val_acc,\n",
    "                'val_loss': val_loss,\n",
    "                'final_epoch': len(history['train_loss'])\n",
    "            })\n",
    "            \n",
    "            print(f\"Validation Accuracy: {val_acc:.2f}%\")\n",
    "            \n",
    "            # Update best\n",
    "            if val_acc > best_score:\n",
    "                best_score = val_acc\n",
    "                best_params = params.copy()\n",
    "                print(f\"🎯 New best score: {best_score:.2f}%\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Trial failed: {e}\")\n",
    "            trial_results.append({\n",
    "                'trial': trial + 1,\n",
    "                'params': params.copy(),\n",
    "                'error': str(e)\n",
    "            })\n",
    "    \n",
    "    # Display results\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"HYPERPARAMETER OPTIMIZATION RESULTS\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Create results DataFrame\n",
    "    successful_trials = [r for r in trial_results if 'error' not in r]\n",
    "    \n",
    "    if successful_trials:\n",
    "        df = pd.DataFrame([\n",
    "            {\n",
    "                'Trial': r['trial'],\n",
    "                'Accuracy': f\"{r['val_acc']:.2f}%\",\n",
    "                'Loss': f\"{r['val_loss']:.4f}\",\n",
    "                'LR': r['params'].get('learning_rate', 'N/A'),\n",
    "                'Batch Size': r['params'].get('batch_size', 'N/A'),\n",
    "                'Dropout': r['params'].get('dropout_rate', 'N/A'),\n",
    "                'Hidden Size': r['params'].get('hidden_size', 'N/A'),\n",
    "                'Layers': r['params'].get('num_layers', 'N/A')\n",
    "            }\n",
    "            for r in successful_trials\n",
    "        ])\n",
    "        \n",
    "        print(df.to_string(index=False))\n",
    "        \n",
    "        # Plot optimization results\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        \n",
    "        # Plot accuracy vs trial\n",
    "        plt.subplot(2, 2, 1)\n",
    "        trials = [r['trial'] for r in successful_trials]\n",
    "        accs = [r['val_acc'] for r in successful_trials]\n",
    "        plt.plot(trials, accs, 'bo-')\n",
    "        plt.title('Validation Accuracy vs Trial')\n",
    "        plt.xlabel('Trial')\n",
    "        plt.ylabel('Accuracy (%)')\n",
    "        plt.grid(True)\n",
    "        \n",
    "        # Plot learning rate vs accuracy\n",
    "        plt.subplot(2, 2, 2)\n",
    "        lrs = [r['params']['learning_rate'] for r in successful_trials]\n",
    "        plt.scatter(lrs, accs, alpha=0.7)\n",
    "        plt.xscale('log')\n",
    "        plt.title('Learning Rate vs Accuracy')\n",
    "        plt.xlabel('Learning Rate')\n",
    "        plt.ylabel('Accuracy (%)')\n",
    "        plt.grid(True)\n",
    "        \n",
    "        # Plot batch size vs accuracy\n",
    "        plt.subplot(2, 2, 3)\n",
    "        batch_sizes = [r['params']['batch_size'] for r in successful_trials]\n",
    "        plt.scatter(batch_sizes, accs, alpha=0.7)\n",
    "        plt.title('Batch Size vs Accuracy')\n",
    "        plt.xlabel('Batch Size')\n",
    "        plt.ylabel('Accuracy (%)')\n",
    "        plt.grid(True)\n",
    "        \n",
    "        # Plot dropout vs accuracy\n",
    "        plt.subplot(2, 2, 4)\n",
    "        dropouts = [r['params']['dropout_rate'] for r in successful_trials]\n",
    "        plt.scatter(dropouts, accs, alpha=0.7)\n",
    "        plt.title('Dropout Rate vs Accuracy')\n",
    "        plt.xlabel('Dropout Rate')\n",
    "        plt.ylabel('Accuracy (%)')\n",
    "        plt.grid(True)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    print(f\"\\n🏆 Best hyperparameters for {model_type.upper()}:\")\n",
    "    print(f\"   Score: {best_score:.2f}%\")\n",
    "    print(f\"   Parameters: {best_params}\")\n",
    "    \n",
    "    return best_params, best_score, trial_results\n",
    "\n",
    "def train_optimized_model(X, y, model_type, best_params):\n",
    "    \"\"\"Train model with optimized hyperparameters.\"\"\"\n",
    "    \n",
    "    print(f\"\\n🚀 Training optimized {model_type.upper()} model...\")\n",
    "    \n",
    "    # Prepare data\n",
    "    train_loader, val_loader, test_loader = prepare_dataloaders(\n",
    "        X, y, model_type, batch_size=best_params.get('batch_size', 32)\n",
    "    )\n",
    "    \n",
    "    # Create optimized model\n",
    "    if model_type == 'cnn':\n",
    "        model = CNNModel(dropout_rate=best_params.get('dropout_rate', 0.3))\n",
    "    elif model_type == 'lstm':\n",
    "        model = LSTMModel(\n",
    "            hidden_size=best_params.get('hidden_size', 128),\n",
    "            num_layers=best_params.get('num_layers', 2),\n",
    "            dropout_rate=best_params.get('dropout_rate', 0.3)\n",
    "        )\n",
    "    elif model_type == 'cnn_lstm':\n",
    "        model = CNNLSTMModel(\n",
    "            lstm_hidden_size=best_params.get('hidden_size', 128),\n",
    "            lstm_num_layers=best_params.get('num_layers', 2),\n",
    "            dropout_rate=best_params.get('dropout_rate', 0.3)\n",
    "        )\n",
    "    else:\n",
    "        model = create_model(model_type)\n",
    "    \n",
    "    # Train with optimal parameters\n",
    "    trainer = ModelTrainer(\n",
    "        model, \n",
    "        device=device, \n",
    "        learning_rate=best_params.get('learning_rate', 0.001)\n",
    "    )\n",
    "    \n",
    "    history = trainer.train(train_loader, val_loader, epochs=EPOCHS)\n",
    "    \n",
    "    # Final evaluation\n",
    "    test_loss, test_acc = trainer.validate_epoch(test_loader)\n",
    "    \n",
    "    print(f\"\\n✅ Optimized {model_type.upper()} Results:\")\n",
    "    print(f\"   Test Accuracy: {test_acc:.2f}%\")\n",
    "    print(f\"   Test Loss: {test_loss:.4f}\")\n",
    "    \n",
    "    return trainer.model, history, test_acc\n",
    "\n",
    "# Run hyperparameter optimization (optional)\n",
    "OPTIMIZE_HYPERPARAMETERS = False  # Set to True to run optimization\n",
    "\n",
    "if OPTIMIZE_HYPERPARAMETERS and 'X' in locals() and 'y' in locals():\n",
    "    print(\"🔬 Starting hyperparameter optimization...\")\n",
    "    \n",
    "    # Choose model to optimize\n",
    "    model_to_optimize = 'cnn'  # Change to 'lstm' or 'cnn_lstm' as needed\n",
    "    \n",
    "    # Run optimization\n",
    "    best_params, best_score, optimization_results = optimize_hyperparameters(\n",
    "        X, y, model_type=model_to_optimize, max_trials=10\n",
    "    )\n",
    "    \n",
    "    # Train final optimized model\n",
    "    if best_params:\n",
    "        optimized_model, optimized_history, optimized_score = train_optimized_model(\n",
    "            X, y, model_to_optimize, best_params\n",
    "        )\n",
    "        \n",
    "        print(f\"\\n🎯 Optimization completed!\")\n",
    "        print(f\"   Improvement: {optimized_score:.2f}% vs baseline\")\n",
    "    \n",
    "else:\n",
    "    print(\"⚠️ Hyperparameter optimization disabled\")\n",
    "    print(\"Set OPTIMIZE_HYPERPARAMETERS = True to enable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdaff4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Export and Deployment Preparation\n",
    "def save_model(model, model_name, save_path=\"./models/\"):\n",
    "    \"\"\"Save trained model for deployment.\"\"\"\n",
    "    \n",
    "    import os\n",
    "    \n",
    "    # Create directory if it doesn't exist\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    \n",
    "    # Save model\n",
    "    model_path = os.path.join(save_path, f\"{model_name}.pth\")\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    \n",
    "    # Save complete model (including architecture)\n",
    "    complete_model_path = os.path.join(save_path, f\"{model_name}_complete.pth\")\n",
    "    torch.save(model, complete_model_path)\n",
    "    \n",
    "    print(f\"✅ Model saved:\")\n",
    "    print(f\"   State dict: {model_path}\")\n",
    "    print(f\"   Complete model: {complete_model_path}\")\n",
    "    \n",
    "    return model_path, complete_model_path\n",
    "\n",
    "def load_model(model_path, model_class=None):\n",
    "    \"\"\"Load saved model for inference.\"\"\"\n",
    "    \n",
    "    try:\n",
    "        if model_class is not None:\n",
    "            # Load state dict into model class\n",
    "            model = model_class()\n",
    "            model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "        else:\n",
    "            # Load complete model\n",
    "            model = torch.load(model_path, map_location=device)\n",
    "        \n",
    "        model.eval()\n",
    "        print(f\"✅ Model loaded from {model_path}\")\n",
    "        return model\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error loading model: {e}\")\n",
    "        return None\n",
    "\n",
    "def export_model_info(training_results, save_path=\"./models/\"):\n",
    "    \"\"\"Export model information and metadata.\"\"\"\n",
    "    \n",
    "    import json\n",
    "    import os\n",
    "    \n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    \n",
    "    # Prepare model info\n",
    "    model_info = {\n",
    "        'training_timestamp': pd.Timestamp.now().isoformat(),\n",
    "        'models': {},\n",
    "        'dataset_info': {\n",
    "            'total_samples': len(X) if 'X' in locals() else 0,\n",
    "            'input_shape': [64, 64, 3],\n",
    "            'output_classes': 2,\n",
    "            'class_names': ['No Press', 'Key Press']\n",
    "        },\n",
    "        'training_config': {\n",
    "            'epochs': EPOCHS,\n",
    "            'batch_size': BATCH_SIZE,\n",
    "            'learning_rate': LEARNING_RATE,\n",
    "            'device': str(device)\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Add model-specific info\n",
    "    for model_name, result in training_results.items():\n",
    "        if 'error' not in result:\n",
    "            model_info['models'][model_name] = {\n",
    "                'test_accuracy': float(result['test_acc']),\n",
    "                'test_loss': float(result['test_loss']),\n",
    "                'training_epochs': len(result['history']['train_loss']),\n",
    "                'best_val_accuracy': float(max(result['history']['val_acc'])),\n",
    "                'best_val_loss': float(min(result['history']['val_loss'])),\n",
    "                'model_size_mb': sum(p.numel() * p.element_size() for p in result['model'].parameters()) / 1024 / 1024\n",
    "            }\n",
    "    \n",
    "    # Save info\n",
    "    info_path = os.path.join(save_path, \"model_info.json\")\n",
    "    with open(info_path, 'w') as f:\n",
    "        json.dump(model_info, f, indent=2)\n",
    "    \n",
    "    print(f\"✅ Model info saved to {info_path}\")\n",
    "    return model_info\n",
    "\n",
    "def create_inference_script(best_model_name, save_path=\"./\"):\n",
    "    \"\"\"Create a standalone inference script.\"\"\"\n",
    "    \n",
    "    inference_script = f'''\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "# Model Architecture (copy from notebook)\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, dropout_rate=0.3):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.fc1 = nn.Linear(128 * 8 * 8, 256)\n",
    "        self.fc2 = nn.Linear(256, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "class KeypressDetector:\n",
    "    def __init__(self, model_path, device='cpu'):\n",
    "        self.device = torch.device(device)\n",
    "        self.model = CNNModel()\n",
    "        self.model.load_state_dict(torch.load(model_path, map_location=self.device))\n",
    "        self.model.eval()\n",
    "        \n",
    "    def preprocess_image(self, image):\n",
    "        \"\"\"Preprocess image for inference.\"\"\"\n",
    "        if isinstance(image, str):\n",
    "            # Load from file\n",
    "            image = Image.open(image).convert('RGB')\n",
    "        \n",
    "        # Resize to 64x64\n",
    "        image = image.resize((64, 64))\n",
    "        \n",
    "        # Convert to array and normalize\n",
    "        image_array = np.array(image).astype(np.float32) / 255.0\n",
    "        \n",
    "        # Add batch dimension and rearrange channels\n",
    "        image_tensor = torch.FloatTensor(image_array).permute(2, 0, 1).unsqueeze(0)\n",
    "        \n",
    "        return image_tensor.to(self.device)\n",
    "    \n",
    "    def predict(self, image):\n",
    "        \"\"\"Predict keypress for an image.\"\"\"\n",
    "        with torch.no_grad():\n",
    "            image_tensor = self.preprocess_image(image)\n",
    "            output = self.model(image_tensor)\n",
    "            probability = torch.sigmoid(output).cpu().numpy()[0][0]\n",
    "            prediction = int(probability > 0.5)\n",
    "            \n",
    "        return prediction, probability\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize detector\n",
    "    detector = KeypressDetector(\"models/{best_model_name}.pth\")\n",
    "    \n",
    "    # Example prediction\n",
    "    # prediction, probability = detector.predict(\"path/to/image.jpg\")\n",
    "    # print(f\"Prediction: {{'Press' if prediction else 'No Press'}}, Probability: {{probability:.3f}}\")\n",
    "'''\n",
    "    \n",
    "    script_path = os.path.join(save_path, \"keypress_inference.py\")\n",
    "    with open(script_path, 'w') as f:\n",
    "        f.write(inference_script)\n",
    "    \n",
    "    print(f\"✅ Inference script saved to {script_path}\")\n",
    "    return script_path\n",
    "\n",
    "def create_deployment_requirements():\n",
    "    \"\"\"Create requirements.txt for deployment.\"\"\"\n",
    "    \n",
    "    requirements = [\n",
    "        \"torch>=1.9.0\",\n",
    "        \"torchvision>=0.10.0\",\n",
    "        \"numpy>=1.21.0\",\n",
    "        \"opencv-python>=4.5.0\",\n",
    "        \"Pillow>=8.3.0\",\n",
    "        \"scikit-learn>=1.0.0\",\n",
    "        \"matplotlib>=3.4.0\",\n",
    "        \"seaborn>=0.11.0\",\n",
    "        \"pandas>=1.3.0\",\n",
    "        \"tqdm>=4.62.0\"\n",
    "    ]\n",
    "    \n",
    "    with open(\"requirements.txt\", 'w') as f:\n",
    "        f.write(\"\\\\n\".join(requirements))\n",
    "    \n",
    "    print(\"✅ Requirements.txt created\")\n",
    "    return requirements\n",
    "\n",
    "# Export models and create deployment files\n",
    "if 'training_results' in locals():\n",
    "    print(\"📦 Preparing models for deployment...\")\n",
    "    \n",
    "    # Find best model\n",
    "    best_model_name = max(training_results.keys(), \n",
    "                         key=lambda x: training_results[x]['test_acc'] if 'error' not in training_results[x] else 0)\n",
    "    \n",
    "    print(f\"🏆 Best model: {best_model_name.upper()}\")\n",
    "    \n",
    "    # Save all models\n",
    "    saved_models = {}\n",
    "    for model_name, result in training_results.items():\n",
    "        if 'error' not in result:\n",
    "            model_path, complete_path = save_model(result['model'], model_name)\n",
    "            saved_models[model_name] = {\n",
    "                'state_dict_path': model_path,\n",
    "                'complete_path': complete_path\n",
    "            }\n",
    "    \n",
    "    # Export model information\n",
    "    model_info = export_model_info(training_results)\n",
    "    \n",
    "    # Create inference script\n",
    "    inference_script_path = create_inference_script(best_model_name)\n",
    "    \n",
    "    # Create requirements\n",
    "    requirements = create_deployment_requirements()\n",
    "    \n",
    "    print(f\"\\\\n🎉 Deployment preparation completed!\")\n",
    "    print(f\"   Best model: {best_model_name.upper()} ({training_results[best_model_name]['test_acc']:.2f}%)\")\n",
    "    print(f\"   Total models saved: {len(saved_models)}\")\n",
    "    print(f\"   Inference script: keypress_inference.py\")\n",
    "    print(f\"   Requirements: requirements.txt\")\n",
    "    print(f\"   Model info: models/model_info.json\")\n",
    "    \n",
    "    # Display final summary\n",
    "    print(f\"\\\\n{'='*60}\")\n",
    "    print(f\"FINAL TRAINING SUMMARY\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    for model_name, result in training_results.items():\n",
    "        if 'error' not in result:\n",
    "            print(f\"{model_name.upper():12} - Accuracy: {result['test_acc']:5.2f}% | Loss: {result['test_loss']:.4f}\")\n",
    "    \n",
    "    print(f\"\\\\n🚀 Ready for deployment!\")\n",
    "    \n",
    "else:\n",
    "    print(\"❌ No training results available for export\")\n",
    "    print(\"Please run the training cell first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d451009d",
   "metadata": {},
   "source": [
    "# 🎯 Training Complete - Summary & Next Steps\n",
    "\n",
    "## 📊 What We've Accomplished\n",
    "\n",
    "This comprehensive notebook provides a complete multi-model training pipeline for keypress detection:\n",
    "\n",
    "### 🤖 **Multiple Model Architectures**\n",
    "- **CNN Model**: Convolutional Neural Network for image classification\n",
    "- **LSTM Model**: Long Short-Term Memory for sequence processing\n",
    "- **CNN+LSTM Model**: Combined approach for spatial-temporal features\n",
    "- **ResNet Model**: Deep residual network for robust feature extraction\n",
    "- **Transformer Model**: Attention-based architecture for advanced pattern recognition\n",
    "\n",
    "### 🔧 **Training Infrastructure**\n",
    "- **ModelTrainer Class**: Unified training loop with early stopping\n",
    "- **Custom Dataset**: PyTorch dataset for keypress data\n",
    "- **Data Augmentation**: Random transforms for better generalization\n",
    "- **Cross-validation**: Robust model evaluation\n",
    "- **Hyperparameter Optimization**: Automatic tuning for best performance\n",
    "\n",
    "### 📈 **Analysis & Evaluation**\n",
    "- **Comprehensive Metrics**: Accuracy, Precision, Recall, F1-Score, AUC\n",
    "- **Visualization**: Training curves, confusion matrices, prediction samples\n",
    "- **Model Comparison**: Side-by-side performance analysis\n",
    "- **Speed Testing**: Inference performance evaluation\n",
    "\n",
    "### 🚀 **Deployment Ready**\n",
    "- **Model Export**: Save trained models for production\n",
    "- **Inference Script**: Standalone prediction code\n",
    "- **Requirements**: Complete dependency list\n",
    "- **Documentation**: Model metadata and configuration\n",
    "\n",
    "## 🎮 **Integration with Video Labeler**\n",
    "\n",
    "This notebook perfectly complements your `video_labeler.py` tool:\n",
    "\n",
    "1. **Data Flow**: Video Labeler → JSON Training Data → This Notebook → Trained Models\n",
    "2. **Format Compatibility**: Direct support for video labeler output format\n",
    "3. **Real-time Integration**: Trained models can be used in real-time detection\n",
    "\n",
    "## 🔄 **Recommended Workflow**\n",
    "\n",
    "1. **Label Data**: Use `video_labeler.py` to create training dataset\n",
    "2. **Train Models**: Run this notebook to train multiple architectures\n",
    "3. **Evaluate**: Compare model performance and select best one\n",
    "4. **Deploy**: Use exported models in your keypress detection system\n",
    "5. **Iterate**: Collect more data and retrain for better performance\n",
    "\n",
    "## 🎯 **Next Steps**\n",
    "\n",
    "### **Immediate Actions**\n",
    "- [ ] Run the notebook with your labeled data\n",
    "- [ ] Compare model performance and select best architecture\n",
    "- [ ] Export the best model for deployment\n",
    "- [ ] Test inference speed on your target hardware\n",
    "\n",
    "### **Advanced Improvements**\n",
    "- [ ] Collect more diverse training data\n",
    "- [ ] Experiment with data augmentation techniques\n",
    "- [ ] Try ensemble methods combining multiple models\n",
    "- [ ] Implement online learning for continuous improvement\n",
    "\n",
    "### **Production Deployment**\n",
    "- [ ] Integrate best model into your detection pipeline\n",
    "- [ ] Set up model versioning and monitoring\n",
    "- [ ] Create automated retraining pipeline\n",
    "- [ ] Add performance metrics tracking\n",
    "\n",
    "## 🤝 **Support & Resources**\n",
    "\n",
    "- **Model Files**: All trained models saved in `./models/` directory\n",
    "- **Inference Script**: `keypress_inference.py` for standalone predictions\n",
    "- **Documentation**: `model_info.json` contains all training metadata\n",
    "- **Requirements**: `requirements.txt` for deployment environment\n",
    "\n",
    "## 🎉 **Ready to Deploy!**\n",
    "\n",
    "Your keypress detection system is now ready for production use. The trained models can accurately detect key presses in real-time video streams, providing the foundation for your hand gesture recognition application.\n",
    "\n",
    "---\n",
    "\n",
    "*Happy Training! 🚀*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71daa06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Model\n",
    "def create_callbacks(model_name=\"keypress_model\"):\n",
    "    \"\"\"Create callbacks for training.\"\"\"\n",
    "    \n",
    "    # Create model directory\n",
    "    model_dir = f\"models/{model_name}\"\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    \n",
    "    callbacks = [\n",
    "        # Model checkpoint - save best model\n",
    "        keras.callbacks.ModelCheckpoint(\n",
    "            filepath=f\"{model_dir}/best_model.h5\",\n",
    "            monitor='val_accuracy',\n",
    "            save_best_only=True,\n",
    "            save_weights_only=False,\n",
    "            mode='max',\n",
    "            verbose=1\n",
    "        ),\n",
    "        \n",
    "        # Early stopping\n",
    "        keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=15,\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        \n",
    "        # Learning rate reduction\n",
    "        keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=7,\n",
    "            min_lr=1e-7,\n",
    "            verbose=1\n",
    "        ),\n",
    "        \n",
    "        # CSV logger\n",
    "        keras.callbacks.CSVLogger(\n",
    "            f\"{model_dir}/training_log.csv\",\n",
    "            append=True\n",
    "        ),\n",
    "        \n",
    "        # TensorBoard\n",
    "        keras.callbacks.TensorBoard(\n",
    "            log_dir=f\"{model_dir}/tensorboard_logs\",\n",
    "            histogram_freq=1,\n",
    "            write_graph=True,\n",
    "            write_images=True\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    return callbacks\n",
    "\n",
    "def train_model(model, train_data, val_data, epochs=100, model_name=\"keypress_model\"):\n",
    "    \"\"\"Train the model with callbacks.\"\"\"\n",
    "    \n",
    "    print(f\"Starting training for {epochs} epochs...\")\n",
    "    print(f\"Model will be saved to: models/{model_name}/\")\n",
    "    \n",
    "    # Create callbacks\n",
    "    callbacks = create_callbacks(model_name)\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        train_data,\n",
    "        validation_data=val_data,\n",
    "        epochs=epochs,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    return history\n",
    "\n",
    "def plot_training_history(history):\n",
    "    \"\"\"Plot training history.\"\"\"\n",
    "    \n",
    "    if not history:\n",
    "        print(\"No training history available\")\n",
    "        return\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Plot training & validation accuracy\n",
    "    axes[0, 0].plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    axes[0, 0].plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    axes[0, 0].set_title('Model Accuracy')\n",
    "    axes[0, 0].set_xlabel('Epoch')\n",
    "    axes[0, 0].set_ylabel('Accuracy')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True)\n",
    "    \n",
    "    # Plot training & validation loss\n",
    "    axes[0, 1].plot(history.history['loss'], label='Training Loss')\n",
    "    axes[0, 1].plot(history.history['val_loss'], label='Validation Loss')\n",
    "    axes[0, 1].set_title('Model Loss')\n",
    "    axes[0, 1].set_xlabel('Epoch')\n",
    "    axes[0, 1].set_ylabel('Loss')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True)\n",
    "    \n",
    "    # Plot precision\n",
    "    if 'precision' in history.history:\n",
    "        axes[1, 0].plot(history.history['precision'], label='Training Precision')\n",
    "        axes[1, 0].plot(history.history['val_precision'], label='Validation Precision')\n",
    "        axes[1, 0].set_title('Model Precision')\n",
    "        axes[1, 0].set_xlabel('Epoch')\n",
    "        axes[1, 0].set_ylabel('Precision')\n",
    "        axes[1, 0].legend()\n",
    "        axes[1, 0].grid(True)\n",
    "    \n",
    "    # Plot recall\n",
    "    if 'recall' in history.history:\n",
    "        axes[1, 1].plot(history.history['recall'], label='Training Recall')\n",
    "        axes[1, 1].plot(history.history['val_recall'], label='Validation Recall')\n",
    "        axes[1, 1].set_title('Model Recall')\n",
    "        axes[1, 1].set_xlabel('Epoch')\n",
    "        axes[1, 1].set_ylabel('Recall')\n",
    "        axes[1, 1].legend()\n",
    "        axes[1, 1].grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Train the model\n",
    "if 'model' in locals() and 'data_splits' in locals():\n",
    "    print(\"Starting model training...\")\n",
    "    \n",
    "    # Create model directory\n",
    "    os.makedirs(\"models\", exist_ok=True)\n",
    "    \n",
    "    # Train the model\n",
    "    history = train_model(\n",
    "        model=model,\n",
    "        train_data=train_gen,\n",
    "        val_data=val_gen,\n",
    "        epochs=50,  # Start with 50 epochs\n",
    "        model_name=\"cnn_lstm_keypress\"\n",
    "    )\n",
    "    \n",
    "    # Plot training history\n",
    "    plot_training_history(history)\n",
    "    \n",
    "    print(\"Training completed!\")\n",
    "    \n",
    "else:\n",
    "    print(\"Model or data not available for training\")\n",
    "    print(\"Please ensure you have:\")\n",
    "    print(\"1. Loaded and preprocessed training data\")\n",
    "    print(\"2. Created the model\")\n",
    "    print(\"3. Prepared data splits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fb7519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Model Performance\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    \"\"\"Evaluate model on test data.\"\"\"\n",
    "    \n",
    "    print(\"Evaluating model on test data...\")\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = model.predict(X_test, verbose=1)\n",
    "    y_pred = np.argmax(predictions, axis=1)\n",
    "    y_true = np.argmax(y_test, axis=1)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "    \n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average='weighted')\n",
    "    recall = recall_score(y_true, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    \n",
    "    print(f\"Test Results:\")\n",
    "    print(f\"  - Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"  - Precision: {precision:.4f}\")\n",
    "    print(f\"  - Recall: {recall:.4f}\")\n",
    "    print(f\"  - F1-Score: {f1:.4f}\")\n",
    "    \n",
    "    return y_pred, y_true, predictions\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, class_names=['Not Pressed', 'Pressed']):\n",
    "    \"\"\"Plot confusion matrix.\"\"\"\n",
    "    \n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.show()\n",
    "    \n",
    "    # Print detailed metrics\n",
    "    print(\"\\nDetailed Classification Report:\")\n",
    "    print(classification_report(y_true, y_pred, target_names=class_names))\n",
    "\n",
    "def plot_prediction_confidence(predictions, y_true, num_samples=100):\n",
    "    \"\"\"Plot prediction confidence distribution.\"\"\"\n",
    "    \n",
    "    # Select random samples\n",
    "    indices = np.random.choice(len(predictions), min(num_samples, len(predictions)), replace=False)\n",
    "    \n",
    "    confidence_scores = np.max(predictions[indices], axis=1)\n",
    "    true_labels = y_true[indices]\n",
    "    \n",
    "    # Separate by correct/incorrect predictions\n",
    "    pred_labels = np.argmax(predictions[indices], axis=1)\n",
    "    correct_mask = (pred_labels == true_labels)\n",
    "    \n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    # Plot confidence for correct predictions\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.hist(confidence_scores[correct_mask], bins=20, alpha=0.7, \n",
    "             color='green', label='Correct Predictions')\n",
    "    plt.hist(confidence_scores[~correct_mask], bins=20, alpha=0.7, \n",
    "             color='red', label='Incorrect Predictions')\n",
    "    plt.xlabel('Prediction Confidence')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Prediction Confidence Distribution')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot confidence by class\n",
    "    plt.subplot(1, 2, 2)\n",
    "    for class_idx in range(2):\n",
    "        class_mask = (true_labels == class_idx)\n",
    "        plt.hist(confidence_scores[class_mask], bins=20, alpha=0.7, \n",
    "                 label=f'Class {class_idx}')\n",
    "    plt.xlabel('Prediction Confidence')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Confidence by True Class')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def analyze_errors(X_test, y_true, y_pred, predictions, num_errors=8):\n",
    "    \"\"\"Analyze prediction errors.\"\"\"\n",
    "    \n",
    "    # Find incorrect predictions\n",
    "    incorrect_indices = np.where(y_true != y_pred)[0]\n",
    "    \n",
    "    if len(incorrect_indices) == 0:\n",
    "        print(\"No prediction errors found!\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Found {len(incorrect_indices)} prediction errors out of {len(y_true)} samples\")\n",
    "    print(f\"Error rate: {len(incorrect_indices)/len(y_true):.2%}\")\n",
    "    \n",
    "    # Show some error cases\n",
    "    num_to_show = min(num_errors, len(incorrect_indices))\n",
    "    error_indices = np.random.choice(incorrect_indices, num_to_show, replace=False)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "    fig.suptitle('Prediction Errors Analysis', fontsize=16)\n",
    "    \n",
    "    for i, idx in enumerate(error_indices):\n",
    "        row = i // 4\n",
    "        col = i % 4\n",
    "        \n",
    "        axes[row, col].imshow(X_test[idx])\n",
    "        \n",
    "        true_label = \"Pressed\" if y_true[idx] == 1 else \"Not Pressed\"\n",
    "        pred_label = \"Pressed\" if y_pred[idx] == 1 else \"Not Pressed\"\n",
    "        confidence = predictions[idx][y_pred[idx]]\n",
    "        \n",
    "        axes[row, col].set_title(f'True: {true_label}\\nPred: {pred_label}\\nConf: {confidence:.3f}')\n",
    "        axes[row, col].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Evaluate the model\n",
    "if 'model' in locals() and 'data_splits' in locals():\n",
    "    # Load best model if available\n",
    "    try:\n",
    "        best_model = keras.models.load_model(\"models/cnn_lstm_keypress/best_model.h5\")\n",
    "        print(\"Loaded best model from checkpoint\")\n",
    "        model = best_model\n",
    "    except:\n",
    "        print(\"Using current model (no checkpoint found)\")\n",
    "    \n",
    "    # Evaluate on test data\n",
    "    y_pred, y_true, predictions = evaluate_model(model, data_splits['X_test'], data_splits['y_test'])\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    plot_confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    # Plot prediction confidence\n",
    "    plot_prediction_confidence(predictions, y_true)\n",
    "    \n",
    "    # Analyze errors\n",
    "    analyze_errors(data_splits['X_test'], y_true, y_pred, predictions)\n",
    "    \n",
    "else:\n",
    "    print(\"Model or data not available for evaluation\")\n",
    "    print(\"Please ensure you have trained the model first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874caa5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real-time Inference Testing\n",
    "def create_inference_pipeline(model, target_key='t', model_path='best_v2.pt'):\n",
    "    \"\"\"Create inference pipeline for real-time testing.\"\"\"\n",
    "    \n",
    "    from ultralytics import YOLO\n",
    "    \n",
    "    # Load YOLO model for key detection\n",
    "    yolo_model = YOLO(model_path)\n",
    "    \n",
    "    def predict_keypress(frame, key_bbox=None):\n",
    "        \"\"\"Predict keypress from a single frame.\"\"\"\n",
    "        \n",
    "        if key_bbox is None:\n",
    "            # Detect key in frame\n",
    "            results = yolo_model(frame)\n",
    "            \n",
    "            for result in results:\n",
    "                if result.boxes is not None:\n",
    "                    for box in result.boxes:\n",
    "                        if result.names[int(box.cls)] == target_key:\n",
    "                            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
    "                            key_bbox = (int(x1), int(y1), int(x2), int(y2))\n",
    "                            break\n",
    "            \n",
    "            if key_bbox is None:\n",
    "                return None, None  # Key not found\n",
    "        \n",
    "        # Extract and preprocess key region\n",
    "        x1, y1, x2, y2 = key_bbox\n",
    "        \n",
    "        # Expand bounding box by 20% (same as video labeler)\n",
    "        width = x2 - x1\n",
    "        height = y2 - y1\n",
    "        expand_x = width * 0.2\n",
    "        expand_y = height * 0.2\n",
    "        \n",
    "        exp_x1 = max(0, int(x1 - expand_x))\n",
    "        exp_y1 = max(0, int(y1 - expand_y))\n",
    "        exp_x2 = min(frame.shape[1], int(x2 + expand_x))\n",
    "        exp_y2 = min(frame.shape[0], int(y2 + expand_y))\n",
    "        \n",
    "        # Extract key region\n",
    "        key_region = frame[exp_y1:exp_y2, exp_x1:exp_x2]\n",
    "        \n",
    "        # Resize to model input size\n",
    "        key_region = cv2.resize(key_region, (64, 64))\n",
    "        \n",
    "        # Normalize\n",
    "        key_region = key_region.astype(np.float32) / 255.0\n",
    "        \n",
    "        # Add batch dimension\n",
    "        key_region = np.expand_dims(key_region, axis=0)\n",
    "        \n",
    "        # Make prediction\n",
    "        prediction = model.predict(key_region, verbose=0)\n",
    "        \n",
    "        # Get probability and class\n",
    "        prob = prediction[0]\n",
    "        predicted_class = np.argmax(prob)\n",
    "        confidence = prob[predicted_class]\n",
    "        \n",
    "        return predicted_class, confidence\n",
    "    \n",
    "    return predict_keypress\n",
    "\n",
    "def test_on_video(video_path, model, target_key='t', output_path=None):\n",
    "    \"\"\"Test model on a video file.\"\"\"\n",
    "    \n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Cannot open video {video_path}\")\n",
    "        return\n",
    "    \n",
    "    # Get video properties\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    print(f\"Video: {video_path}\")\n",
    "    print(f\"FPS: {fps}, Size: {width}x{height}, Frames: {total_frames}\")\n",
    "    \n",
    "    # Create inference pipeline\n",
    "    predict_keypress = create_inference_pipeline(model, target_key)\n",
    "    \n",
    "    # Setup video writer if output path is provided\n",
    "    if output_path:\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "    \n",
    "    # Process video\n",
    "    frame_count = 0\n",
    "    key_bbox = None\n",
    "    predictions = []\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        frame_count += 1\n",
    "        \n",
    "        # Predict keypress\n",
    "        predicted_class, confidence = predict_keypress(frame, key_bbox)\n",
    "        \n",
    "        if predicted_class is not None:\n",
    "            predictions.append({\n",
    "                'frame': frame_count,\n",
    "                'prediction': predicted_class,\n",
    "                'confidence': confidence\n",
    "            })\n",
    "            \n",
    "            # Draw prediction on frame\n",
    "            label = \"PRESSED\" if predicted_class == 1 else \"NOT PRESSED\"\n",
    "            color = (0, 255, 0) if predicted_class == 1 else (0, 0, 255)\n",
    "            \n",
    "            cv2.putText(frame, f\"{label} ({confidence:.3f})\", \n",
    "                       (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)\n",
    "            \n",
    "            # Draw key bounding box if found\n",
    "            if key_bbox:\n",
    "                x1, y1, x2, y2 = key_bbox\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "        \n",
    "        # Write frame to output video\n",
    "        if output_path:\n",
    "            out.write(frame)\n",
    "        \n",
    "        # Display frame (optional)\n",
    "        cv2.imshow('Keypress Detection', frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    # Cleanup\n",
    "    cap.release()\n",
    "    if output_path:\n",
    "        out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    print(f\"Processed {frame_count} frames\")\n",
    "    print(f\"Made {len(predictions)} predictions\")\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "def analyze_video_predictions(predictions):\n",
    "    \"\"\"Analyze predictions from video inference.\"\"\"\n",
    "    \n",
    "    if not predictions:\n",
    "        print(\"No predictions to analyze\")\n",
    "        return\n",
    "    \n",
    "    # Convert to DataFrame for easier analysis\n",
    "    df = pd.DataFrame(predictions)\n",
    "    \n",
    "    # Basic statistics\n",
    "    print(f\"Video Prediction Analysis:\")\n",
    "    print(f\"  - Total frames predicted: {len(df)}\")\n",
    "    print(f\"  - Pressed frames: {sum(df['prediction'] == 1)}\")\n",
    "    print(f\"  - Not pressed frames: {sum(df['prediction'] == 0)}\")\n",
    "    print(f\"  - Average confidence: {df['confidence'].mean():.3f}\")\n",
    "    \n",
    "    # Plot predictions over time\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    \n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(df['frame'], df['prediction'], 'b-', linewidth=2)\n",
    "    plt.title('Key Press Predictions Over Time')\n",
    "    plt.ylabel('Prediction (0=Not Pressed, 1=Pressed)')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(df['frame'], df['confidence'], 'r-', linewidth=2)\n",
    "    plt.title('Prediction Confidence Over Time')\n",
    "    plt.xlabel('Frame Number')\n",
    "    plt.ylabel('Confidence')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Test the model on video\n",
    "if 'model' in locals():\n",
    "    # Example usage (uncomment and modify paths as needed)\n",
    "    \n",
    "    # Test on a video file\n",
    "    # video_path = \"path/to/your/test_video.mp4\"\n",
    "    # output_path = \"keypress_predictions.mp4\"\n",
    "    \n",
    "    # predictions = test_on_video(video_path, model, target_key='t', output_path=output_path)\n",
    "    # analyze_video_predictions(predictions)\n",
    "    \n",
    "    print(\"Real-time inference pipeline created!\")\n",
    "    print(\"To test on a video:\")\n",
    "    print(\"1. Uncomment the lines above\")\n",
    "    print(\"2. Set video_path to your test video\")\n",
    "    print(\"3. Set output_path for result video\")\n",
    "    print(\"4. Run the cell\")\n",
    "    \n",
    "else:\n",
    "    print(\"Model not available for inference testing\")\n",
    "    print(\"Please train the model first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6d60ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Optimization and Fine-tuning\n",
    "def create_optimized_model(input_shape=(64, 64, 3), num_classes=2):\n",
    "    \"\"\"Create optimized CNN model with better architecture.\"\"\"\n",
    "    \n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    \n",
    "    # Initial convolution\n",
    "    x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    # Residual block 1\n",
    "    residual = x\n",
    "    x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Add()([x, residual])\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = layers.Dropout(0.25)(x)\n",
    "    \n",
    "    # Residual block 2\n",
    "    residual = layers.Conv2D(64, (1, 1), padding='same')(x)\n",
    "    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Add()([x, residual])\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = layers.Dropout(0.25)(x)\n",
    "    \n",
    "    # Residual block 3\n",
    "    residual = layers.Conv2D(128, (1, 1), padding='same')(x)\n",
    "    x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Add()([x, residual])\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = layers.Dropout(0.25)(x)\n",
    "    \n",
    "    # Attention mechanism\n",
    "    attention = layers.Conv2D(128, (1, 1), activation='sigmoid')(x)\n",
    "    x = layers.Multiply()([x, attention])\n",
    "    \n",
    "    # Global pooling and dense layers\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dense(512, activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    \n",
    "    x = layers.Dense(256, activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    \n",
    "    # Output layer\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "def fine_tune_model(base_model, X_train, y_train, X_val, y_val, epochs=20):\n",
    "    \"\"\"Fine-tune model with different learning rates.\"\"\"\n",
    "    \n",
    "    print(\"Fine-tuning model...\")\n",
    "    \n",
    "    # Freeze some layers\n",
    "    for layer in base_model.layers[:-4]:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    # Compile with lower learning rate\n",
    "    base_model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    # Create callbacks\n",
    "    callbacks = [\n",
    "        keras.callbacks.EarlyStopping(\n",
    "            monitor='val_accuracy',\n",
    "            patience=10,\n",
    "            restore_best_weights=True\n",
    "        ),\n",
    "        keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=5,\n",
    "            min_lr=1e-7\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    # Fine-tune\n",
    "    history = base_model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=epochs,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    return history\n",
    "\n",
    "def hyperparameter_tuning(X_train, y_train, X_val, y_val):\n",
    "    \"\"\"Perform hyperparameter tuning.\"\"\"\n",
    "    \n",
    "    print(\"Performing hyperparameter tuning...\")\n",
    "    \n",
    "    # Define hyperparameter search space\n",
    "    lr_values = [0.001, 0.0005, 0.0001]\n",
    "    batch_sizes = [16, 32, 64]\n",
    "    dropout_rates = [0.3, 0.5, 0.7]\n",
    "    \n",
    "    best_accuracy = 0\n",
    "    best_params = {}\n",
    "    results = []\n",
    "    \n",
    "    for lr in lr_values:\n",
    "        for batch_size in batch_sizes:\n",
    "            for dropout in dropout_rates:\n",
    "                print(f\"Testing: LR={lr}, Batch={batch_size}, Dropout={dropout}\")\n",
    "                \n",
    "                # Create model with current hyperparameters\n",
    "                model = create_optimized_model()\n",
    "                \n",
    "                # Modify dropout rate\n",
    "                for layer in model.layers:\n",
    "                    if isinstance(layer, layers.Dropout):\n",
    "                        layer.rate = dropout\n",
    "                \n",
    "                # Compile model\n",
    "                model.compile(\n",
    "                    optimizer=keras.optimizers.Adam(learning_rate=lr),\n",
    "                    loss='categorical_crossentropy',\n",
    "                    metrics=['accuracy']\n",
    "                )\n",
    "                \n",
    "                # Train for a few epochs\n",
    "                history = model.fit(\n",
    "                    X_train, y_train,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    epochs=10,\n",
    "                    batch_size=batch_size,\n",
    "                    verbose=0\n",
    "                )\n",
    "                \n",
    "                # Get best validation accuracy\n",
    "                val_accuracy = max(history.history['val_accuracy'])\n",
    "                \n",
    "                results.append({\n",
    "                    'lr': lr,\n",
    "                    'batch_size': batch_size,\n",
    "                    'dropout': dropout,\n",
    "                    'val_accuracy': val_accuracy\n",
    "                })\n",
    "                \n",
    "                if val_accuracy > best_accuracy:\n",
    "                    best_accuracy = val_accuracy\n",
    "                    best_params = {\n",
    "                        'lr': lr,\n",
    "                        'batch_size': batch_size,\n",
    "                        'dropout': dropout\n",
    "                    }\n",
    "                \n",
    "                print(f\"  Validation accuracy: {val_accuracy:.4f}\")\n",
    "    \n",
    "    print(f\"\\nBest parameters: {best_params}\")\n",
    "    print(f\"Best validation accuracy: {best_accuracy:.4f}\")\n",
    "    \n",
    "    return best_params, results\n",
    "\n",
    "def ensemble_prediction(models, X_test):\n",
    "    \"\"\"Create ensemble predictions from multiple models.\"\"\"\n",
    "    \n",
    "    predictions = []\n",
    "    \n",
    "    for model in models:\n",
    "        pred = model.predict(X_test, verbose=0)\n",
    "        predictions.append(pred)\n",
    "    \n",
    "    # Average predictions\n",
    "    ensemble_pred = np.mean(predictions, axis=0)\n",
    "    \n",
    "    return ensemble_pred\n",
    "\n",
    "# Model optimization example\n",
    "if 'data_splits' in locals():\n",
    "    print(\"Starting model optimization...\")\n",
    "    \n",
    "    # Create optimized model\n",
    "    optimized_model = create_optimized_model()\n",
    "    \n",
    "    print(\"Optimized Model Architecture:\")\n",
    "    optimized_model.summary()\n",
    "    \n",
    "    # Compile optimized model\n",
    "    optimized_model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    # Optional: Perform hyperparameter tuning (this will take a while)\n",
    "    # best_params, tuning_results = hyperparameter_tuning(\n",
    "    #     data_splits['X_train'], data_splits['y_train'],\n",
    "    #     data_splits['X_val'], data_splits['y_val']\n",
    "    # )\n",
    "    \n",
    "    print(\"Model optimization setup completed!\")\n",
    "    print(\"Uncomment hyperparameter tuning section to run full optimization\")\n",
    "    \n",
    "else:\n",
    "    print(\"Data not available for model optimization\")\n",
    "    print(\"Please prepare training data first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a199ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export Model for Production\n",
    "def export_model(model, model_name=\"keypress_detector\"):\n",
    "    \"\"\"Export trained model in multiple formats for production.\"\"\"\n",
    "    \n",
    "    # Create export directory\n",
    "    export_dir = f\"exported_models/{model_name}\"\n",
    "    os.makedirs(export_dir, exist_ok=True)\n",
    "    \n",
    "    print(f\"Exporting model to {export_dir}/...\")\n",
    "    \n",
    "    # 1. Save in Keras H5 format\n",
    "    h5_path = f\"{export_dir}/{model_name}.h5\"\n",
    "    model.save(h5_path)\n",
    "    print(f\"✓ Saved H5 model: {h5_path}\")\n",
    "    \n",
    "    # 2. Save in TensorFlow SavedModel format\n",
    "    savedmodel_path = f\"{export_dir}/{model_name}_savedmodel\"\n",
    "    model.save(savedmodel_path)\n",
    "    print(f\"✓ Saved TensorFlow SavedModel: {savedmodel_path}\")\n",
    "    \n",
    "    # 3. Save model weights only\n",
    "    weights_path = f\"{export_dir}/{model_name}_weights.h5\"\n",
    "    model.save_weights(weights_path)\n",
    "    print(f\"✓ Saved model weights: {weights_path}\")\n",
    "    \n",
    "    # 4. Export to TensorFlow Lite for mobile deployment\n",
    "    try:\n",
    "        converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "        converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "        tflite_model = converter.convert()\n",
    "        \n",
    "        tflite_path = f\"{export_dir}/{model_name}.tflite\"\n",
    "        with open(tflite_path, 'wb') as f:\n",
    "            f.write(tflite_model)\n",
    "        print(f\"✓ Saved TensorFlow Lite model: {tflite_path}\")\n",
    "        \n",
    "        # Get model size\n",
    "        model_size = os.path.getsize(tflite_path) / 1024  # KB\n",
    "        print(f\"  TensorFlow Lite model size: {model_size:.1f} KB\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"✗ TensorFlow Lite export failed: {e}\")\n",
    "    \n",
    "    # 5. Save model architecture as JSON\n",
    "    architecture_path = f\"{export_dir}/{model_name}_architecture.json\"\n",
    "    with open(architecture_path, 'w') as f:\n",
    "        f.write(model.to_json())\n",
    "    print(f\"✓ Saved model architecture: {architecture_path}\")\n",
    "    \n",
    "    # 6. Save model summary\n",
    "    summary_path = f\"{export_dir}/{model_name}_summary.txt\"\n",
    "    with open(summary_path, 'w') as f:\n",
    "        model.summary(print_fn=lambda x: f.write(x + '\\n'))\n",
    "    print(f\"✓ Saved model summary: {summary_path}\")\n",
    "    \n",
    "    return export_dir\n",
    "\n",
    "def create_inference_class(model_path, target_key='t'):\n",
    "    \"\"\"Create a production-ready inference class.\"\"\"\n",
    "    \n",
    "    inference_code = f'''\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "class KeypressDetector:\n",
    "    def __init__(self, model_path=\"{model_path}\", yolo_model_path=\"best_v2.pt\"):\n",
    "        \"\"\"Initialize the keypress detector.\"\"\"\n",
    "        self.model = tf.keras.models.load_model(model_path)\n",
    "        self.yolo_model = YOLO(yolo_model_path)\n",
    "        self.target_key = \"{target_key}\"\n",
    "        self.key_bbox = None\n",
    "        \n",
    "    def detect_key_region(self, frame):\n",
    "        \"\"\"Detect key region in frame using YOLO.\"\"\"\n",
    "        results = self.yolo_model(frame)\n",
    "        \n",
    "        for result in results:\n",
    "            if result.boxes is not None:\n",
    "                for box in result.boxes:\n",
    "                    if result.names[int(box.cls)] == self.target_key:\n",
    "                        x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
    "                        \n",
    "                        # Expand bounding box by 20%\n",
    "                        width = x2 - x1\n",
    "                        height = y2 - y1\n",
    "                        expand_x = width * 0.2\n",
    "                        expand_y = height * 0.2\n",
    "                        \n",
    "                        exp_x1 = max(0, int(x1 - expand_x))\n",
    "                        exp_y1 = max(0, int(y1 - expand_y))\n",
    "                        exp_x2 = min(frame.shape[1], int(x2 + expand_x))\n",
    "                        exp_y2 = min(frame.shape[0], int(y2 + expand_y))\n",
    "                        \n",
    "                        self.key_bbox = (exp_x1, exp_y1, exp_x2, exp_y2)\n",
    "                        return self.key_bbox\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def preprocess_frame(self, frame, bbox=None):\n",
    "        \"\"\"Preprocess frame for model input.\"\"\"\n",
    "        if bbox is None:\n",
    "            bbox = self.key_bbox\n",
    "        \n",
    "        if bbox is None:\n",
    "            return None\n",
    "        \n",
    "        # Extract key region\n",
    "        x1, y1, x2, y2 = bbox\n",
    "        key_region = frame[y1:y2, x1:x2]\n",
    "        \n",
    "        # Resize to model input size\n",
    "        key_region = cv2.resize(key_region, (64, 64))\n",
    "        \n",
    "        # Normalize\n",
    "        key_region = key_region.astype(np.float32) / 255.0\n",
    "        \n",
    "        # Add batch dimension\n",
    "        key_region = np.expand_dims(key_region, axis=0)\n",
    "        \n",
    "        return key_region\n",
    "    \n",
    "    def predict(self, frame, bbox=None):\n",
    "        \"\"\"Predict keypress from frame.\"\"\"\n",
    "        # Preprocess frame\n",
    "        input_data = self.preprocess_frame(frame, bbox)\n",
    "        \n",
    "        if input_data is None:\n",
    "            return None, None\n",
    "        \n",
    "        # Make prediction\n",
    "        prediction = self.model.predict(input_data, verbose=0)\n",
    "        \n",
    "        # Get result\n",
    "        prob = prediction[0]\n",
    "        predicted_class = np.argmax(prob)\n",
    "        confidence = prob[predicted_class]\n",
    "        \n",
    "        return predicted_class, confidence\n",
    "    \n",
    "    def process_video(self, video_path, output_path=None):\n",
    "        \"\"\"Process entire video and return predictions.\"\"\"\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        \n",
    "        if not cap.isOpened():\n",
    "            raise ValueError(f\"Cannot open video: {{video_path}}\")\n",
    "        \n",
    "        # Get video properties\n",
    "        fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        \n",
    "        # Setup video writer if output path provided\n",
    "        if output_path:\n",
    "            fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "            out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "        \n",
    "        predictions = []\n",
    "        frame_count = 0\n",
    "        \n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            frame_count += 1\n",
    "            \n",
    "            # Detect key region on first frame\n",
    "            if self.key_bbox is None:\n",
    "                self.detect_key_region(frame)\n",
    "            \n",
    "            # Make prediction\n",
    "            predicted_class, confidence = self.predict(frame)\n",
    "            \n",
    "            if predicted_class is not None:\n",
    "                predictions.append({{\n",
    "                    'frame': frame_count,\n",
    "                    'prediction': predicted_class,\n",
    "                    'confidence': confidence\n",
    "                }})\n",
    "                \n",
    "                # Draw prediction on frame\n",
    "                label = \"PRESSED\" if predicted_class == 1 else \"NOT PRESSED\"\n",
    "                color = (0, 255, 0) if predicted_class == 1 else (0, 0, 255)\n",
    "                \n",
    "                cv2.putText(frame, f\"{{label}} ({{confidence:.3f}})\", \n",
    "                           (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)\n",
    "                \n",
    "                # Draw bounding box\n",
    "                if self.key_bbox:\n",
    "                    x1, y1, x2, y2 = self.key_bbox\n",
    "                    cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "            \n",
    "            # Write frame to output\n",
    "            if output_path:\n",
    "                out.write(frame)\n",
    "        \n",
    "        # Cleanup\n",
    "        cap.release()\n",
    "        if output_path:\n",
    "            out.release()\n",
    "        \n",
    "        return predictions\n",
    "\n",
    "# Example usage:\n",
    "# detector = KeypressDetector()\n",
    "# predictions = detector.process_video(\"input_video.mp4\", \"output_video.mp4\")\n",
    "'''\n",
    "    \n",
    "    return inference_code\n",
    "\n",
    "def save_inference_code(code, export_dir):\n",
    "    \"\"\"Save inference code to file.\"\"\"\n",
    "    code_path = f\"{export_dir}/keypress_detector.py\"\n",
    "    with open(code_path, 'w') as f:\n",
    "        f.write(code)\n",
    "    print(f\"✓ Saved inference code: {code_path}\")\n",
    "    return code_path\n",
    "\n",
    "def create_deployment_requirements():\n",
    "    \"\"\"Create requirements.txt for deployment.\"\"\"\n",
    "    requirements = '''\n",
    "tensorflow>=2.8.0\n",
    "opencv-python>=4.5.0\n",
    "ultralytics>=8.0.0\n",
    "numpy>=1.20.0\n",
    "'''\n",
    "    return requirements\n",
    "\n",
    "def save_deployment_files(export_dir):\n",
    "    \"\"\"Save deployment files.\"\"\"\n",
    "    \n",
    "    # Save requirements.txt\n",
    "    requirements_path = f\"{export_dir}/requirements.txt\"\n",
    "    with open(requirements_path, 'w') as f:\n",
    "        f.write(create_deployment_requirements())\n",
    "    print(f\"✓ Saved requirements: {requirements_path}\")\n",
    "    \n",
    "    # Save README\n",
    "    readme_content = f'''\n",
    "# Keypress Detection Model\n",
    "\n",
    "This directory contains the trained keypress detection model and inference code.\n",
    "\n",
    "## Files:\n",
    "- `keypress_detector.h5`: Trained Keras model\n",
    "- `keypress_detector_savedmodel/`: TensorFlow SavedModel format\n",
    "- `keypress_detector.tflite`: TensorFlow Lite model for mobile\n",
    "- `keypress_detector.py`: Inference class for production use\n",
    "- `requirements.txt`: Required Python packages\n",
    "\n",
    "## Usage:\n",
    "```python\n",
    "from keypress_detector import KeypressDetector\n",
    "\n",
    "# Initialize detector\n",
    "detector = KeypressDetector(\"keypress_detector.h5\")\n",
    "\n",
    "# Process video\n",
    "predictions = detector.process_video(\"input.mp4\", \"output.mp4\")\n",
    "```\n",
    "\n",
    "## Installation:\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "Generated on: {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}\n",
    "'''\n",
    "    \n",
    "    readme_path = f\"{export_dir}/README.md\"\n",
    "    with open(readme_path, 'w') as f:\n",
    "        f.write(readme_content)\n",
    "    print(f\"✓ Saved README: {readme_path}\")\n",
    "\n",
    "# Export the model for production\n",
    "if 'model' in locals():\n",
    "    # Export model\n",
    "    export_dir = export_model(model, \"keypress_detector\")\n",
    "    \n",
    "    # Create inference code\n",
    "    model_path = f\"{export_dir}/keypress_detector.h5\"\n",
    "    inference_code = create_inference_class(model_path)\n",
    "    save_inference_code(inference_code, export_dir)\n",
    "    \n",
    "    # Save deployment files\n",
    "    save_deployment_files(export_dir)\n",
    "    \n",
    "    print(f\"\\n🎉 Model successfully exported to: {export_dir}\")\n",
    "    print(\"\\nProduction-ready files created:\")\n",
    "    print(\"- Model files (H5, SavedModel, TensorFlow Lite)\")\n",
    "    print(\"- Inference code (keypress_detector.py)\")\n",
    "    print(\"- Requirements and documentation\")\n",
    "    print(\"\\nYour model is ready for deployment!\")\n",
    "    \n",
    "else:\n",
    "    print(\"Model not available for export\")\n",
    "    print(\"Please train the model first\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
